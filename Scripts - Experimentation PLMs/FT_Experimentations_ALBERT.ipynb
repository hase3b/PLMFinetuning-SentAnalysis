{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"72b653b2a5a64ac09646dd9f9f943801":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ca31cf00f33e431086a1fd840c1ec1a1","IPY_MODEL_f974d40852674a6aa7256b2f19927aa9","IPY_MODEL_40b1e622f9e147c3af595ba4633645e5"],"layout":"IPY_MODEL_93e3912e1e724d01b1dc2c3458c5ba0e"}},"ca31cf00f33e431086a1fd840c1ec1a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9aebfd8aebe44d61a77b65c8bed284aa","placeholder":"​","style":"IPY_MODEL_376e5ecac0294510a1ec2337e033beb6","value":"Map: 100%"}},"f974d40852674a6aa7256b2f19927aa9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_db9d8a09fa6643828bfa844d3380f7f3","max":8000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3ed81ff6ee3e4e048e3dd4bfb997d05c","value":8000}},"40b1e622f9e147c3af595ba4633645e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_881c6fe2b0dd40e1a75d99a57b70e450","placeholder":"​","style":"IPY_MODEL_29e25dd314714fcabe51b3359c64f14d","value":" 8000/8000 [00:07&lt;00:00, 1109.45 examples/s]"}},"93e3912e1e724d01b1dc2c3458c5ba0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9aebfd8aebe44d61a77b65c8bed284aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"376e5ecac0294510a1ec2337e033beb6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db9d8a09fa6643828bfa844d3380f7f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ed81ff6ee3e4e048e3dd4bfb997d05c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"881c6fe2b0dd40e1a75d99a57b70e450":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29e25dd314714fcabe51b3359c64f14d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2300846a42cf4320a2334fac6e8d1276":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e1b3c6a68897456dbf2873d7cb598d08","IPY_MODEL_3f231b796633421688e36c165fb0b75b","IPY_MODEL_1467532e119942039d423945d7ba3724"],"layout":"IPY_MODEL_a9dc10ca26b248c3a19d6ececba46f11"}},"e1b3c6a68897456dbf2873d7cb598d08":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75d6b430c08b430dbd43e0a5ea595ebb","placeholder":"​","style":"IPY_MODEL_e776bc85300a4302a5378f8cb5671b19","value":"Map: 100%"}},"3f231b796633421688e36c165fb0b75b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_af867fa5cf5649b1a765a6281d73b160","max":2000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a669ca1a25434ddd9d2a720037693def","value":2000}},"1467532e119942039d423945d7ba3724":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_522bc4aa551e4a43bb6d2bae098d6e21","placeholder":"​","style":"IPY_MODEL_f40e896126d14009a71dd837ef147c53","value":" 2000/2000 [00:01&lt;00:00, 1151.43 examples/s]"}},"a9dc10ca26b248c3a19d6ececba46f11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75d6b430c08b430dbd43e0a5ea595ebb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e776bc85300a4302a5378f8cb5671b19":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af867fa5cf5649b1a765a6281d73b160":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a669ca1a25434ddd9d2a720037693def":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"522bc4aa551e4a43bb6d2bae098d6e21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f40e896126d14009a71dd837ef147c53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c7f8deb78954a4d9b78f3e661db65d8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_de3e29ce5ec64d0f88a5963a50466564","IPY_MODEL_b04c36eca0d6487f8d06f6fd1d9bb084","IPY_MODEL_9b00eeb368074deea88dd431ab4e8c8e"],"layout":"IPY_MODEL_07e4167bf03c46a39e58e7667231d370"}},"de3e29ce5ec64d0f88a5963a50466564":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd58ae91d34843a3a3ed44643a72c277","placeholder":"​","style":"IPY_MODEL_cd15492c83424caab76c8f197774548b","value":"Map: 100%"}},"b04c36eca0d6487f8d06f6fd1d9bb084":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_813faf21b45d4ee7857a375d353acbda","max":5000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9e5ca873be1f48a39599c027a39453e8","value":5000}},"9b00eeb368074deea88dd431ab4e8c8e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcdecbfc46f94a669a7477c010dcb206","placeholder":"​","style":"IPY_MODEL_0f6a30ceea3a4c47a3bccc8787d0f73d","value":" 5000/5000 [00:06&lt;00:00, 752.12 examples/s]"}},"07e4167bf03c46a39e58e7667231d370":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd58ae91d34843a3a3ed44643a72c277":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd15492c83424caab76c8f197774548b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"813faf21b45d4ee7857a375d353acbda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e5ca873be1f48a39599c027a39453e8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bcdecbfc46f94a669a7477c010dcb206":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f6a30ceea3a4c47a3bccc8787d0f73d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10381688,"sourceType":"datasetVersion","datasetId":6431167}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### **Installing dependencies**","metadata":{"id":"lGx3k9oTN6dU"}},{"cell_type":"code","source":"!pip install ipython-autotime gdown evaluate accelerate bitsandbytes peft loralib huggingface_hub transformers peft","metadata":{"id":"iqrl56zeCrIp","colab":{"base_uri":"https://localhost:8080/"},"outputId":"eb99b496-f862-4887-a102-648ea49630b0","trusted":true,"execution":{"iopub.status.busy":"2025-01-06T11:07:26.677077Z","iopub.execute_input":"2025-01-06T11:07:26.677430Z","iopub.status.idle":"2025-01-06T11:07:37.985578Z","shell.execute_reply.started":"2025-01-06T11:07:26.677396Z","shell.execute_reply":"2025-01-06T11:07:37.984450Z"}},"outputs":[{"name":"stdout","text":"Collecting ipython-autotime\n  Downloading ipython_autotime-0.3.2-py2.py3-none-any.whl.metadata (1.4 kB)\nRequirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\nCollecting peft\n  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\nCollecting loralib\n  Downloading loralib-0.1.2-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.24.7)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\nRequirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipython-autotime) (7.34.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\nRequirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.5)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.4.1+cu121)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\nRequirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\nCollecting huggingface_hub\n  Downloading huggingface_hub-0.27.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.8.30)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\nRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (71.0.4)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.7.5)\nRequirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (5.7.1)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (3.0.47)\nRequirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (2.18.0)\nRequirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.9.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.11.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.4)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.13)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading ipython_autotime-0.3.2-py2.py3-none-any.whl (7.0 kB)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading peft-0.14.0-py3-none-any.whl (374 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading loralib-0.1.2-py3-none-any.whl (10 kB)\nDownloading huggingface_hub-0.27.0-py3-none-any.whl (450 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.5/450.5 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: loralib, huggingface_hub, ipython-autotime, bitsandbytes, peft, evaluate\n  Attempting uninstall: huggingface_hub\n    Found existing installation: huggingface-hub 0.24.7\n    Uninstalling huggingface-hub-0.24.7:\n      Successfully uninstalled huggingface-hub-0.24.7\nSuccessfully installed bitsandbytes-0.45.0 evaluate-0.4.3 huggingface_hub-0.27.0 ipython-autotime-0.3.2 loralib-0.1.2 peft-0.14.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"##### **Importing dependencies**","metadata":{"id":"JYV5TiU2zwQM"}},{"cell_type":"code","source":"%load_ext autotime\nimport pandas as pd\nimport numpy as np\nimport nltk\nimport os\nimport zipfile\nimport tarfile\nimport re\nimport gdown\nimport gzip\nimport shutil\nimport wandb\nimport time\nimport torch\nimport psutil\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, precision_recall_fscore_support\nfrom datasets import Dataset\n\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSeq2SeqLM,\n    AutoModelForCausalLM,\n    AutoModelForSequenceClassification,\n    DistilBertTokenizerFast,\n    DistilBertForSequenceClassification,\n    RobertaTokenizerFast, \n    RobertaForSequenceClassification,\n    GPT2TokenizerFast, \n    GPT2ForSequenceClassification,\n    AlbertTokenizer, \n    AlbertForSequenceClassification,\n    GenerationConfig,\n    TrainingArguments,\n    Trainer,\n    pipeline,\n    BitsAndBytesConfig,\n    DataCollatorForSeq2Seq,\n    DataCollatorWithPadding,\n    AdamW,\n    get_scheduler\n)\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm import tqdm\nimport time\nimport evaluate\nfrom peft import (\n    LoraConfig,\n    get_peft_model,\n    TaskType,\n    PeftModel,\n    PeftConfig,\n)\nfrom huggingface_hub import login\nimport kagglehub\n\n# from nltk.corpus import stopwords\n# from nltk import word_tokenize\n# from nltk.stem import WordNetLemmatizer\n# from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\n# from sklearn.metrics import accuracy_score\n# from sklearn.naive_bayes import MultinomialNB\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.neighbors import KNeighborsClassifier\n# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n# from google.colab import files\n# from scipy.sparse import hstack\n# from gensim.models import Word2Vec\n\nimport warnings\n\n# Suppress specific warnings\nwarnings.filterwarnings(\"ignore\", message=\".*clean_up_tokenization_spaces.*\")\nwarnings.filterwarnings(\"ignore\", message=\"Some weights of DistilBertForSequenceClassification were not initialized.*\")\nwarnings.filterwarnings(\"ignore\", message=\"Some weights of AlbertForSequenceClassification were not initialized.*\")\nwarnings.filterwarnings(\"ignore\", message=\".*evaluation_strategy.*\")\nwarnings.filterwarnings(\"ignore\", message=\".*gather along dimension 0.*\")\nwarnings.filterwarnings(\"ignore\", message=\".*GradScaler.*\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s58Pnf7Lz0Q2","outputId":"2ea414ab-9e3c-406f-b2db-0df497fd7455","trusted":true,"execution":{"iopub.status.busy":"2025-01-06T11:07:37.987150Z","iopub.execute_input":"2025-01-06T11:07:37.987452Z","iopub.status.idle":"2025-01-06T11:08:10.350528Z","shell.execute_reply.started":"2025-01-06T11:07:37.987426Z","shell.execute_reply":"2025-01-06T11:08:10.349548Z"}},"outputs":[{"name":"stdout","text":"time: 32.3 s (started: 2025-01-06 11:07:38 +00:00)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Disable wandb Logging\nos.environ[\"WANDB_MODE\"] = \"disabled\"\nwandb.init()\n\n# Check for GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T11:08:14.183050Z","iopub.execute_input":"2025-01-06T11:08:14.183776Z","iopub.status.idle":"2025-01-06T11:08:20.002785Z","shell.execute_reply.started":"2025-01-06T11:08:14.183727Z","shell.execute_reply":"2025-01-06T11:08:20.001947Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\ntime: 5.81 s (started: 2025-01-06 11:08:14 +00:00)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"##### **Supporting functions**","metadata":{}},{"cell_type":"code","source":"def clean_review(review):\n    review = re.sub(r'<.*?>', '', review)\n    review = re.sub(r'http\\S+|www\\S+|https\\S+', '', review, flags=re.MULTILINE)\n    review = review.strip()\n    return review\n\ndef preprocess_function(examples):\n    inputs = tokenizer(examples[\"review\"], truncation=True, padding=True, max_length=512)\n    inputs[\"labels\"] = [1 if label.lower() == \"positive\" else 0 for label in examples[\"sentiment\"]]\n    return inputs\n\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    acc = accuracy_score(labels, preds)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T11:08:21.434515Z","iopub.execute_input":"2025-01-06T11:08:21.435217Z","iopub.status.idle":"2025-01-06T11:08:21.442452Z","shell.execute_reply.started":"2025-01-06T11:08:21.435186Z","shell.execute_reply":"2025-01-06T11:08:21.441350Z"}},"outputs":[{"name":"stdout","text":"time: 840 µs (started: 2025-01-06 11:08:21 +00:00)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"##### **Loading data**","metadata":{}},{"cell_type":"code","source":"train_df_full = pd.read_csv(\"/kaggle/input/imdb-dataset-3/train.csv\")\ntrain_df = train_df_full.sample(n=3000, random_state=42)\ntrain_df['review'] = train_df['review'].apply(clean_review)\ntrain_df.reset_index(drop=True, inplace=True)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"of1BQo9GbCkM","outputId":"78d1609f-f5f3-4a94-dca4-a9a0a585374a","trusted":true,"execution":{"iopub.status.busy":"2025-01-06T11:08:28.289034Z","iopub.execute_input":"2025-01-06T11:08:28.289336Z","iopub.status.idle":"2025-01-06T11:08:29.323435Z","shell.execute_reply.started":"2025-01-06T11:08:28.289314Z","shell.execute_reply":"2025-01-06T11:08:29.322450Z"}},"outputs":[{"name":"stdout","text":"time: 1.03 s (started: 2025-01-06 11:08:28 +00:00)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"test_df_full = pd.read_csv(\"/kaggle/input/imdb-dataset-3/test.csv\")\ntest_df = test_df_full.sample(n=2000, random_state=42)\ntest_df['review'] = test_df['review'].apply(clean_review)\ntest_df.reset_index(drop=True, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T11:08:29.324701Z","iopub.execute_input":"2025-01-06T11:08:29.324962Z","iopub.status.idle":"2025-01-06T11:08:29.983164Z","shell.execute_reply.started":"2025-01-06T11:08:29.324940Z","shell.execute_reply":"2025-01-06T11:08:29.982241Z"}},"outputs":[{"name":"stdout","text":"time: 654 ms (started: 2025-01-06 11:08:29 +00:00)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from datasets import Dataset\n\ntrain_dataset = Dataset.from_pandas(train_df)\ntest_dataset = Dataset.from_pandas(test_df)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":131,"referenced_widgets":["72b653b2a5a64ac09646dd9f9f943801","ca31cf00f33e431086a1fd840c1ec1a1","f974d40852674a6aa7256b2f19927aa9","40b1e622f9e147c3af595ba4633645e5","93e3912e1e724d01b1dc2c3458c5ba0e","9aebfd8aebe44d61a77b65c8bed284aa","376e5ecac0294510a1ec2337e033beb6","db9d8a09fa6643828bfa844d3380f7f3","3ed81ff6ee3e4e048e3dd4bfb997d05c","881c6fe2b0dd40e1a75d99a57b70e450","29e25dd314714fcabe51b3359c64f14d","2300846a42cf4320a2334fac6e8d1276","e1b3c6a68897456dbf2873d7cb598d08","3f231b796633421688e36c165fb0b75b","1467532e119942039d423945d7ba3724","a9dc10ca26b248c3a19d6ececba46f11","75d6b430c08b430dbd43e0a5ea595ebb","e776bc85300a4302a5378f8cb5671b19","af867fa5cf5649b1a765a6281d73b160","a669ca1a25434ddd9d2a720037693def","522bc4aa551e4a43bb6d2bae098d6e21","f40e896126d14009a71dd837ef147c53","2c7f8deb78954a4d9b78f3e661db65d8","de3e29ce5ec64d0f88a5963a50466564","b04c36eca0d6487f8d06f6fd1d9bb084","9b00eeb368074deea88dd431ab4e8c8e","07e4167bf03c46a39e58e7667231d370","dd58ae91d34843a3a3ed44643a72c277","cd15492c83424caab76c8f197774548b","813faf21b45d4ee7857a375d353acbda","9e5ca873be1f48a39599c027a39453e8","bcdecbfc46f94a669a7477c010dcb206","0f6a30ceea3a4c47a3bccc8787d0f73d"]},"id":"Zw1uk2V9awQL","outputId":"a1432fba-5921-4ce3-9d4d-ef7346229dac","trusted":true,"execution":{"iopub.status.busy":"2025-01-06T11:08:29.984339Z","iopub.execute_input":"2025-01-06T11:08:29.984700Z","iopub.status.idle":"2025-01-06T11:08:30.071635Z","shell.execute_reply.started":"2025-01-06T11:08:29.984674Z","shell.execute_reply":"2025-01-06T11:08:30.070582Z"}},"outputs":[{"name":"stdout","text":"time: 83.4 ms (started: 2025-01-06 11:08:29 +00:00)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"### **Experimentations for ALBERT - Phase 1:** keeping LoRA hyperparams fixed","metadata":{}},{"cell_type":"code","source":"model_checkpoint = \"albert-base-v2\"\ntokenizer = AlbertTokenizer.from_pretrained(model_checkpoint)\nmodel = AlbertForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2).to(device)\n\ntokenized_train = train_dataset.map(preprocess_function, batched=True)\ntokenized_test = test_dataset.map(preprocess_function, batched=True)\n\n# Fixed LoRA parameters\nrank = 8 \ntarget_matrices = [\"attention.query\", \"attention.key\", \"attention.value\"]\nlora_alpha = 16\nlora_dropout = 0.1\n\n# Changing hyperparams for batch size, epochs and learning rates\nbatch_sizes = [4, 8]\nepochs_list = [3, 5]\nlearning_rates = [3e-5, 1e-4]\n\ntraining_dropout = 0.1 # Fixed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T03:18:03.225477Z","iopub.execute_input":"2025-01-06T03:18:03.225801Z","iopub.status.idle":"2025-01-06T03:18:16.121481Z","shell.execute_reply.started":"2025-01-06T03:18:03.225776Z","shell.execute_reply":"2025-01-06T03:18:16.120810Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a4a161ee469458b9592f3315a4c5ad8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8295d37838b54f349b675ad1863ec8f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef9d3179891440e1b710e98e1513134c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc5a49593ac942f58817bedd435e6017"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/47.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbfb7db2f969465fb5e466a65aad1677"}},"metadata":{}},{"name":"stderr","text":"Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd943509f4aa42a784c1c840cf265fdc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95b7885f26734c2aab75e6d18c6b63d1"}},"metadata":{}},{"name":"stdout","text":"time: 12.9 s (started: 2025-01-06 03:18:03 +00:00)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"print(f\"Model is running on device: {model.device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T03:18:23.108538Z","iopub.execute_input":"2025-01-06T03:18:23.108899Z","iopub.status.idle":"2025-01-06T03:18:23.113505Z","shell.execute_reply.started":"2025-01-06T03:18:23.108871Z","shell.execute_reply":"2025-01-06T03:18:23.112696Z"}},"outputs":[{"name":"stdout","text":"Model is running on device: cuda:0\ntime: 519 µs (started: 2025-01-06 03:18:23 +00:00)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"results_phase_1 = []\n\nfor batch_size in batch_sizes:\n    for epochs in epochs_list:\n        for learning_rate in learning_rates:\n            lora_config = LoraConfig(\n                r=rank,\n                lora_alpha=lora_alpha,\n                target_modules=target_matrices,\n                lora_dropout=lora_dropout,\n                task_type=\"SEQ_CLS\"\n            )\n\n            model_with_lora = get_peft_model(model, lora_config)\n            \n            start_time = time.time()\n            print(f\"\\nRunning experiment with: Batch Size: {batch_size}, Epochs: {epochs}, Learning Rate: {learning_rate}\")\n\n            num_parameters = sum(p.numel() for p in model_with_lora.parameters())\n            trainable_parameters = sum(p.numel() for p in model_with_lora.parameters() if p.requires_grad)\n            trainable_percentage = (trainable_parameters / num_parameters) * 100\n            \n            print(f\"Model has {num_parameters:,} total parameters\")\n            print(f\"Model has {trainable_parameters:,} trainable parameters\")\n            print(f\"{trainable_percentage:.2f}% of the parameters are trainable\")\n\n            if torch.cuda.is_available():\n                torch.cuda.empty_cache()\n                gpu_memory = torch.cuda.memory_allocated() / 1024**2  # in MB\n                print(f\"GPU memory allocated: {gpu_memory:.2f} MB\")\n\n            wandb.config.update({\"model/num_parameters\": model.num_parameters()}, allow_val_change=True)\n\n            output_dir = f\"./results_phase1_r{rank}_alpha{lora_alpha}_drop{lora_dropout}_targets{'_'.join(target_matrices)}_bs{batch_size}_epochs{epochs}_lr{learning_rate}\"\n            training_args = TrainingArguments(\n                output_dir=output_dir,\n                evaluation_strategy=\"epoch\",\n                learning_rate=learning_rate,\n                per_device_train_batch_size=batch_size,\n                per_device_eval_batch_size=batch_size,\n                num_train_epochs=epochs,\n                weight_decay=0.01,\n                save_total_limit=1,\n                save_strategy=\"epoch\",\n                logging_dir=\"./logs\",\n                logging_steps=10,\n                load_best_model_at_end=True,\n            )\n\n            trainer = Trainer(\n                model=model_with_lora,\n                args=training_args,\n                train_dataset=tokenized_train,\n                eval_dataset=tokenized_test,\n                tokenizer=tokenizer,\n                compute_metrics=compute_metrics\n            )\n\n            trainer.train()\n            metrics = trainer.evaluate()\n\n            end_time = time.time()\n            elapsed_time = end_time - start_time\n            print(f\"Training time: {elapsed_time:.2f} seconds\")\n\n            results_phase_1.append({\n                \"Model\": \"ALBERT\",\n                \"Batch Size\": batch_size,\n                \"Epochs\": epochs,\n                \"Learning Rate\": learning_rate,\n                \"Rank\": rank,\n                \"Alpha\": lora_alpha,\n                \"LoRA Dropout\": lora_dropout,\n                \"Target Matrices\": target_matrices,\n                \"Accuracy\": metrics[\"eval_accuracy\"],\n                \"Precision\": metrics[\"eval_precision\"],\n                \"Recall\": metrics[\"eval_recall\"],\n                \"F1-Score\": metrics[\"eval_f1\"]                \n            })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T03:18:28.525702Z","iopub.execute_input":"2025-01-06T03:18:28.526004Z","iopub.status.idle":"2025-01-06T05:11:21.513783Z","shell.execute_reply.started":"2025-01-06T03:18:28.525983Z","shell.execute_reply":"2025-01-06T05:11:21.513005Z"}},"outputs":[{"name":"stdout","text":"\nRunning experiment with: Batch Size: 4, Epochs: 3, Learning Rate: 3e-05\nModel has 11,723,524 total parameters\nModel has 38,402 trainable parameters\n0.33% of the parameters are trainable\nGPU memory allocated: 44.73 MB\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1125' max='1125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1125/1125 09:52, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.668600</td>\n      <td>0.670187</td>\n      <td>0.603500</td>\n      <td>0.624403</td>\n      <td>0.603500</td>\n      <td>0.577508</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.506800</td>\n      <td>0.531487</td>\n      <td>0.776000</td>\n      <td>0.783831</td>\n      <td>0.776000</td>\n      <td>0.775257</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.395000</td>\n      <td>0.440732</td>\n      <td>0.820500</td>\n      <td>0.821890</td>\n      <td>0.820500</td>\n      <td>0.820528</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [250/250 00:50]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 646.55 seconds\n\nRunning experiment with: Batch Size: 4, Epochs: 3, Learning Rate: 0.0001\nModel has 11,723,524 total parameters\nModel has 38,402 trainable parameters\n0.33% of the parameters are trainable\nGPU memory allocated: 61.42 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1125' max='1125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1125/1125 10:11, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.245200</td>\n      <td>0.305836</td>\n      <td>0.882500</td>\n      <td>0.883307</td>\n      <td>0.882500</td>\n      <td>0.882533</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.215700</td>\n      <td>0.293271</td>\n      <td>0.911000</td>\n      <td>0.911200</td>\n      <td>0.911000</td>\n      <td>0.910946</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.139600</td>\n      <td>0.291900</td>\n      <td>0.911000</td>\n      <td>0.910997</td>\n      <td>0.911000</td>\n      <td>0.910990</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [250/250 00:50]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 663.68 seconds\n\nRunning experiment with: Batch Size: 4, Epochs: 5, Learning Rate: 3e-05\nModel has 11,723,524 total parameters\nModel has 38,402 trainable parameters\n0.33% of the parameters are trainable\nGPU memory allocated: 61.42 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1875/1875 16:57, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.663000</td>\n      <td>0.668339</td>\n      <td>0.607000</td>\n      <td>0.640289</td>\n      <td>0.607000</td>\n      <td>0.573069</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.366600</td>\n      <td>0.402713</td>\n      <td>0.841000</td>\n      <td>0.846601</td>\n      <td>0.841000</td>\n      <td>0.840752</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.194300</td>\n      <td>0.303722</td>\n      <td>0.882500</td>\n      <td>0.882679</td>\n      <td>0.882500</td>\n      <td>0.882525</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.330500</td>\n      <td>0.292062</td>\n      <td>0.892000</td>\n      <td>0.892036</td>\n      <td>0.892000</td>\n      <td>0.892010</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.294400</td>\n      <td>0.290203</td>\n      <td>0.896000</td>\n      <td>0.896004</td>\n      <td>0.896000</td>\n      <td>0.895980</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [250/250 00:50]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 1068.76 seconds\n\nRunning experiment with: Batch Size: 4, Epochs: 5, Learning Rate: 0.0001\nModel has 11,723,524 total parameters\nModel has 38,402 trainable parameters\n0.33% of the parameters are trainable\nGPU memory allocated: 61.42 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1875/1875 16:57, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.312600</td>\n      <td>0.308228</td>\n      <td>0.880000</td>\n      <td>0.882896</td>\n      <td>0.880000</td>\n      <td>0.879966</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.248700</td>\n      <td>0.293610</td>\n      <td>0.908500</td>\n      <td>0.909243</td>\n      <td>0.908500</td>\n      <td>0.908526</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.118700</td>\n      <td>0.289587</td>\n      <td>0.917000</td>\n      <td>0.917441</td>\n      <td>0.917000</td>\n      <td>0.916922</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.425600</td>\n      <td>0.292842</td>\n      <td>0.916500</td>\n      <td>0.916636</td>\n      <td>0.916500</td>\n      <td>0.916517</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.146300</td>\n      <td>0.291703</td>\n      <td>0.918000</td>\n      <td>0.918211</td>\n      <td>0.918000</td>\n      <td>0.917950</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [250/250 00:50]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 1069.37 seconds\n\nRunning experiment with: Batch Size: 8, Epochs: 3, Learning Rate: 3e-05\nModel has 11,723,524 total parameters\nModel has 38,402 trainable parameters\n0.33% of the parameters are trainable\nGPU memory allocated: 61.42 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 09:47, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.704100</td>\n      <td>0.687831</td>\n      <td>0.544500</td>\n      <td>0.543094</td>\n      <td>0.544500</td>\n      <td>0.539779</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.670500</td>\n      <td>0.663635</td>\n      <td>0.625000</td>\n      <td>0.624928</td>\n      <td>0.625000</td>\n      <td>0.624958</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.643900</td>\n      <td>0.649220</td>\n      <td>0.655500</td>\n      <td>0.655452</td>\n      <td>0.655500</td>\n      <td>0.654646</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:47]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 636.12 seconds\n\nRunning experiment with: Batch Size: 8, Epochs: 3, Learning Rate: 0.0001\nModel has 11,723,524 total parameters\nModel has 38,402 trainable parameters\n0.33% of the parameters are trainable\nGPU memory allocated: 61.42 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 09:46, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.553900</td>\n      <td>0.446333</td>\n      <td>0.811000</td>\n      <td>0.815649</td>\n      <td>0.811000</td>\n      <td>0.810767</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.324100</td>\n      <td>0.285541</td>\n      <td>0.900000</td>\n      <td>0.900990</td>\n      <td>0.900000</td>\n      <td>0.899835</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.210100</td>\n      <td>0.267127</td>\n      <td>0.900000</td>\n      <td>0.900149</td>\n      <td>0.900000</td>\n      <td>0.899945</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:47]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 635.88 seconds\n\nRunning experiment with: Batch Size: 8, Epochs: 5, Learning Rate: 3e-05\nModel has 11,723,524 total parameters\nModel has 38,402 trainable parameters\n0.33% of the parameters are trainable\nGPU memory allocated: 61.42 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='940' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [940/940 16:16, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.703000</td>\n      <td>0.686410</td>\n      <td>0.549000</td>\n      <td>0.548161</td>\n      <td>0.549000</td>\n      <td>0.539804</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.653600</td>\n      <td>0.645013</td>\n      <td>0.669500</td>\n      <td>0.672564</td>\n      <td>0.669500</td>\n      <td>0.669179</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.519100</td>\n      <td>0.527987</td>\n      <td>0.776000</td>\n      <td>0.779537</td>\n      <td>0.776000</td>\n      <td>0.775821</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.399800</td>\n      <td>0.420881</td>\n      <td>0.833000</td>\n      <td>0.833523</td>\n      <td>0.833000</td>\n      <td>0.833048</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.433100</td>\n      <td>0.393097</td>\n      <td>0.847500</td>\n      <td>0.847506</td>\n      <td>0.847500</td>\n      <td>0.847503</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:47]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 1025.85 seconds\n\nRunning experiment with: Batch Size: 8, Epochs: 5, Learning Rate: 0.0001\nModel has 11,723,524 total parameters\nModel has 38,402 trainable parameters\n0.33% of the parameters are trainable\nGPU memory allocated: 61.42 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='940' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [940/940 16:17, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.516300</td>\n      <td>0.390825</td>\n      <td>0.840000</td>\n      <td>0.842739</td>\n      <td>0.840000</td>\n      <td>0.839954</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.321200</td>\n      <td>0.265708</td>\n      <td>0.904500</td>\n      <td>0.905465</td>\n      <td>0.904500</td>\n      <td>0.904525</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.211900</td>\n      <td>0.245570</td>\n      <td>0.911000</td>\n      <td>0.911200</td>\n      <td>0.911000</td>\n      <td>0.910946</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.150200</td>\n      <td>0.244345</td>\n      <td>0.914500</td>\n      <td>0.914637</td>\n      <td>0.914500</td>\n      <td>0.914517</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.278600</td>\n      <td>0.238338</td>\n      <td>0.919000</td>\n      <td>0.919143</td>\n      <td>0.919000</td>\n      <td>0.918960</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:46]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 1026.58 seconds\ntime: 1h 52min 52s (started: 2025-01-06 03:18:28 +00:00)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Testing evaluations saved\nresults_df_phase_1 = pd.DataFrame(results_phase_1)\nresults_df_phase_1.to_csv(\"7_FT_ALBERT_Experiments_FixedLoRA.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T05:12:32.824691Z","iopub.execute_input":"2025-01-06T05:12:32.824987Z","iopub.status.idle":"2025-01-06T05:12:32.834184Z","shell.execute_reply.started":"2025-01-06T05:12:32.824963Z","shell.execute_reply":"2025-01-06T05:12:32.833271Z"}},"outputs":[{"name":"stdout","text":"time: 5.55 ms (started: 2025-01-06 05:12:32 +00:00)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"### **Experimentations for ALBERT - Phase 2:** changing LoRA hyperparameters","metadata":{}},{"cell_type":"code","source":"model_checkpoint = \"albert-base-v2\"\ntokenizer = AlbertTokenizer.from_pretrained(model_checkpoint)\nmodel = AlbertForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2).to(device)\n\ntokenized_train = train_dataset.map(preprocess_function, batched=True)\ntokenized_test = test_dataset.map(preprocess_function, batched=True)\n\n# Fixed parameters for batch size and epochs, etc\nfixed_batch_size = 16\nfixed_epochs = 5\nfixed_learning_rate = 1e-4\ntraining_dropout = 0.1\n\n# LoRA parameter combinations\nranks = [8, 16]\ntarget_matrices_list = [[\"attention.query\"], [\"attention.query\", \"attention.key\"], [\"attention.query\", \"attention.key\", \"attention.value\"]]\nlora_alpha = 16\nlora_dropouts = [0.1, 0.2]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T11:08:49.561062Z","iopub.execute_input":"2025-01-06T11:08:49.561403Z","iopub.status.idle":"2025-01-06T11:09:04.155355Z","shell.execute_reply.started":"2025-01-06T11:08:49.561380Z","shell.execute_reply":"2025-01-06T11:09:04.154337Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95a71a660fe14ce981484ab0e86896b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a654003150e4b20a35f553c6c0e071b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81044dc17ecb4f609bbb4a11e2961aec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d632108bed8b48608c41f7f5a48ac495"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/47.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d512a2be51d94a729629b5439254c79d"}},"metadata":{}},{"name":"stderr","text":"Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13046fe360e24bf2bf36924454576f51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"086afd67757c49ec9a7b6afd9f7c732d"}},"metadata":{}},{"name":"stdout","text":"time: 14.6 s (started: 2025-01-06 11:08:49 +00:00)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"results_phase_2 = []\n\nfor rank in ranks:\n    for target_matrices in target_matrices_list:\n        for lora_dropout in lora_dropouts:\n            lora_config = LoraConfig(\n                r=rank,\n                lora_alpha=lora_alpha,  # Fixed lora_alpha\n                target_modules=target_matrices,\n                lora_dropout=lora_dropout,\n                task_type=\"SEQ_CLS\"\n            )\n\n            model_with_lora = get_peft_model(model, lora_config)\n\n            start_time = time.time()\n            print(f\"\\nRunning experiment with: Rank: {rank}, Target Matrices: {target_matrices}, LoRA Dropout: {lora_dropout}\")\n\n            num_parameters = sum(p.numel() for p in model_with_lora.parameters())\n            trainable_parameters = sum(p.numel() for p in model_with_lora.parameters() if p.requires_grad)\n            trainable_percentage = (trainable_parameters / num_parameters) * 100\n            \n            print(f\"Model has {num_parameters:,} total parameters\")\n            print(f\"Model has {trainable_parameters:,} trainable parameters\")\n            print(f\"{trainable_percentage:.2f}% of the parameters are trainable\")\n\n            if torch.cuda.is_available():\n                torch.cuda.empty_cache()\n                gpu_memory = torch.cuda.memory_allocated() / 1024**2  # in MB\n                print(f\"GPU memory allocated: {gpu_memory:.2f} MB\")\n\n            wandb.config.update({\"model/num_parameters\": model.num_parameters()}, allow_val_change=True)\n\n            output_dir = f\"./results_phase2_r{rank}_alpha{lora_alpha}_drop{lora_dropout}_targets{'_'.join(target_matrices)}_bs{fixed_batch_size}_epochs{fixed_epochs}_lr{fixed_learning_rate}\"\n            training_args = TrainingArguments(\n                output_dir=output_dir,\n                evaluation_strategy=\"epoch\",\n                learning_rate=fixed_learning_rate,\n                per_device_train_batch_size=fixed_batch_size,\n                per_device_eval_batch_size=fixed_batch_size,\n                num_train_epochs=fixed_epochs,\n                weight_decay=0.01,\n                save_total_limit=1,\n                save_strategy=\"epoch\",\n                logging_dir=\"./logs\",\n                logging_steps=10,\n                fp16=True,\n                load_best_model_at_end=True,\n            )\n\n            trainer = Trainer(\n                model=model_with_lora,\n                args=training_args,\n                train_dataset=tokenized_train,\n                eval_dataset=tokenized_test,\n                tokenizer=tokenizer,\n                compute_metrics=compute_metrics\n            )\n\n            trainer.train()\n            metrics = trainer.evaluate()\n\n            end_time = time.time()\n            elapsed_time = end_time - start_time\n            print(f\"Training time: {elapsed_time:.2f} seconds\")\n\n            results_phase_2.append({\n                \"Model\": \"ALBERT\",\n                \"Batch Size\": fixed_batch_size,\n                \"Epochs\": fixed_epochs,\n                \"Learning Rate\": fixed_learning_rate,\n                \"Rank\": rank,\n                \"Alpha\": lora_alpha,  # Fixed alpha\n                \"LoRA Dropout\": lora_dropout,\n                \"Target Matrices\": target_matrices,\n                \"Accuracy\": metrics[\"eval_accuracy\"],\n                \"Precision\": metrics[\"eval_precision\"],\n                \"Recall\": metrics[\"eval_recall\"],\n                \"F1-Score\": metrics[\"eval_f1\"]\n            })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T11:09:23.312572Z","iopub.execute_input":"2025-01-06T11:09:23.312969Z","iopub.status.idle":"2025-01-06T14:15:22.546888Z","shell.execute_reply.started":"2025-01-06T11:09:23.312937Z","shell.execute_reply":"2025-01-06T14:15:22.546005Z"}},"outputs":[{"name":"stdout","text":"\nRunning experiment with: Rank: 8, Target Matrices: ['attention.query'], LoRA Dropout: 0.1\nModel has 11,698,948 total parameters\nModel has 13,826 trainable parameters\n0.12% of the parameters are trainable\nGPU memory allocated: 44.64 MB\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 14:10, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.692400</td>\n      <td>0.674462</td>\n      <td>0.583500</td>\n      <td>0.621132</td>\n      <td>0.583500</td>\n      <td>0.535353</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.620400</td>\n      <td>0.607277</td>\n      <td>0.687000</td>\n      <td>0.691465</td>\n      <td>0.687000</td>\n      <td>0.686398</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.496600</td>\n      <td>0.508597</td>\n      <td>0.760000</td>\n      <td>0.765200</td>\n      <td>0.760000</td>\n      <td>0.759561</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.484300</td>\n      <td>0.442865</td>\n      <td>0.807500</td>\n      <td>0.807750</td>\n      <td>0.807500</td>\n      <td>0.807284</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.415500</td>\n      <td>0.423513</td>\n      <td>0.815000</td>\n      <td>0.815000</td>\n      <td>0.815000</td>\n      <td>0.814918</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:42]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 898.23 seconds\n\nRunning experiment with: Rank: 8, Target Matrices: ['attention.query'], LoRA Dropout: 0.2\nModel has 11,698,948 total parameters\nModel has 13,826 trainable parameters\n0.12% of the parameters are trainable\nGPU memory allocated: 61.67 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 14:14, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.693200</td>\n      <td>0.675770</td>\n      <td>0.580000</td>\n      <td>0.614674</td>\n      <td>0.580000</td>\n      <td>0.531958</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.635500</td>\n      <td>0.625485</td>\n      <td>0.672000</td>\n      <td>0.679291</td>\n      <td>0.672000</td>\n      <td>0.670483</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.517100</td>\n      <td>0.531594</td>\n      <td>0.744000</td>\n      <td>0.748592</td>\n      <td>0.744000</td>\n      <td>0.743600</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.498200</td>\n      <td>0.458264</td>\n      <td>0.798500</td>\n      <td>0.799679</td>\n      <td>0.798500</td>\n      <td>0.797957</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.419700</td>\n      <td>0.433823</td>\n      <td>0.817500</td>\n      <td>0.817781</td>\n      <td>0.817500</td>\n      <td>0.817295</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:41]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 899.08 seconds\n\nRunning experiment with: Rank: 8, Target Matrices: ['attention.query', 'attention.key'], LoRA Dropout: 0.1\nModel has 11,711,236 total parameters\nModel has 26,114 trainable parameters\n0.22% of the parameters are trainable\nGPU memory allocated: 61.72 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 14:34, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.658200</td>\n      <td>0.655283</td>\n      <td>0.625000</td>\n      <td>0.640255</td>\n      <td>0.625000</td>\n      <td>0.608707</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.517000</td>\n      <td>0.513102</td>\n      <td>0.758500</td>\n      <td>0.763171</td>\n      <td>0.758500</td>\n      <td>0.758133</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.357200</td>\n      <td>0.363552</td>\n      <td>0.847500</td>\n      <td>0.847828</td>\n      <td>0.847500</td>\n      <td>0.847340</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.336500</td>\n      <td>0.319395</td>\n      <td>0.871500</td>\n      <td>0.871497</td>\n      <td>0.871500</td>\n      <td>0.871472</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.320700</td>\n      <td>0.309292</td>\n      <td>0.874500</td>\n      <td>0.874729</td>\n      <td>0.874500</td>\n      <td>0.874403</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:43]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 920.27 seconds\n\nRunning experiment with: Rank: 8, Target Matrices: ['attention.query', 'attention.key'], LoRA Dropout: 0.2\nModel has 11,711,236 total parameters\nModel has 26,114 trainable parameters\n0.22% of the parameters are trainable\nGPU memory allocated: 61.86 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 14:34, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.661500</td>\n      <td>0.659641</td>\n      <td>0.618000</td>\n      <td>0.634161</td>\n      <td>0.618000</td>\n      <td>0.599636</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.553900</td>\n      <td>0.542307</td>\n      <td>0.741000</td>\n      <td>0.745163</td>\n      <td>0.741000</td>\n      <td>0.740660</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.392000</td>\n      <td>0.395847</td>\n      <td>0.827000</td>\n      <td>0.826976</td>\n      <td>0.827000</td>\n      <td>0.826981</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.362000</td>\n      <td>0.339497</td>\n      <td>0.859500</td>\n      <td>0.859486</td>\n      <td>0.859500</td>\n      <td>0.859476</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.331300</td>\n      <td>0.326023</td>\n      <td>0.869000</td>\n      <td>0.869467</td>\n      <td>0.869000</td>\n      <td>0.868848</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:42]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 919.86 seconds\n\nRunning experiment with: Rank: 8, Target Matrices: ['attention.query', 'attention.key', 'attention.value'], LoRA Dropout: 0.1\nModel has 11,723,524 total parameters\nModel has 38,402 trainable parameters\n0.33% of the parameters are trainable\nGPU memory allocated: 61.91 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 14:52, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.576500</td>\n      <td>0.551631</td>\n      <td>0.737000</td>\n      <td>0.741676</td>\n      <td>0.737000</td>\n      <td>0.734622</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.280900</td>\n      <td>0.315389</td>\n      <td>0.870500</td>\n      <td>0.872249</td>\n      <td>0.870500</td>\n      <td>0.870510</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.249900</td>\n      <td>0.271304</td>\n      <td>0.888500</td>\n      <td>0.888497</td>\n      <td>0.888500</td>\n      <td>0.888498</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.258300</td>\n      <td>0.261163</td>\n      <td>0.899500</td>\n      <td>0.899493</td>\n      <td>0.899500</td>\n      <td>0.899495</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.268200</td>\n      <td>0.257992</td>\n      <td>0.901500</td>\n      <td>0.901527</td>\n      <td>0.901500</td>\n      <td>0.901508</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:43]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 939.10 seconds\n\nRunning experiment with: Rank: 8, Target Matrices: ['attention.query', 'attention.key', 'attention.value'], LoRA Dropout: 0.2\nModel has 11,723,524 total parameters\nModel has 38,402 trainable parameters\n0.33% of the parameters are trainable\nGPU memory allocated: 62.05 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 14:52, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.585400</td>\n      <td>0.563911</td>\n      <td>0.726500</td>\n      <td>0.732359</td>\n      <td>0.726500</td>\n      <td>0.723430</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.295500</td>\n      <td>0.322439</td>\n      <td>0.869000</td>\n      <td>0.870501</td>\n      <td>0.869000</td>\n      <td>0.869019</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.257000</td>\n      <td>0.275250</td>\n      <td>0.886500</td>\n      <td>0.886515</td>\n      <td>0.886500</td>\n      <td>0.886506</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.266800</td>\n      <td>0.263273</td>\n      <td>0.898500</td>\n      <td>0.898497</td>\n      <td>0.898500</td>\n      <td>0.898498</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.277600</td>\n      <td>0.260102</td>\n      <td>0.900500</td>\n      <td>0.900497</td>\n      <td>0.900500</td>\n      <td>0.900498</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:43]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 938.76 seconds\n\nRunning experiment with: Rank: 16, Target Matrices: ['attention.query'], LoRA Dropout: 0.1\nModel has 11,735,812 total parameters\nModel has 50,690 trainable parameters\n0.43% of the parameters are trainable\nGPU memory allocated: 62.00 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 14:52, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.260300</td>\n      <td>0.249009</td>\n      <td>0.901000</td>\n      <td>0.901000</td>\n      <td>0.901000</td>\n      <td>0.901000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.173200</td>\n      <td>0.249260</td>\n      <td>0.907500</td>\n      <td>0.907882</td>\n      <td>0.907500</td>\n      <td>0.907526</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.175600</td>\n      <td>0.245058</td>\n      <td>0.907000</td>\n      <td>0.907128</td>\n      <td>0.907000</td>\n      <td>0.906954</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.216700</td>\n      <td>0.241744</td>\n      <td>0.912000</td>\n      <td>0.912002</td>\n      <td>0.912000</td>\n      <td>0.911987</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.246300</td>\n      <td>0.240815</td>\n      <td>0.911500</td>\n      <td>0.911548</td>\n      <td>0.911500</td>\n      <td>0.911472</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:43]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 939.35 seconds\n\nRunning experiment with: Rank: 16, Target Matrices: ['attention.query'], LoRA Dropout: 0.2\nModel has 11,735,812 total parameters\nModel has 50,690 trainable parameters\n0.43% of the parameters are trainable\nGPU memory allocated: 62.14 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 14:54, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.214000</td>\n      <td>0.242858</td>\n      <td>0.912000</td>\n      <td>0.912779</td>\n      <td>0.912000</td>\n      <td>0.912025</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.144000</td>\n      <td>0.250011</td>\n      <td>0.913500</td>\n      <td>0.914109</td>\n      <td>0.913500</td>\n      <td>0.913525</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.149700</td>\n      <td>0.244209</td>\n      <td>0.912500</td>\n      <td>0.912531</td>\n      <td>0.912500</td>\n      <td>0.912477</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.189200</td>\n      <td>0.242756</td>\n      <td>0.913000</td>\n      <td>0.913003</td>\n      <td>0.913000</td>\n      <td>0.912987</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.227300</td>\n      <td>0.245166</td>\n      <td>0.913000</td>\n      <td>0.913106</td>\n      <td>0.913000</td>\n      <td>0.912962</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:43]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 940.65 seconds\n\nRunning experiment with: Rank: 16, Target Matrices: ['attention.query', 'attention.key'], LoRA Dropout: 0.1\nModel has 11,748,100 total parameters\nModel has 62,978 trainable parameters\n0.54% of the parameters are trainable\nGPU memory allocated: 62.23 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 14:54, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.240800</td>\n      <td>0.240759</td>\n      <td>0.910500</td>\n      <td>0.910583</td>\n      <td>0.910500</td>\n      <td>0.910514</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.165900</td>\n      <td>0.254935</td>\n      <td>0.900500</td>\n      <td>0.902198</td>\n      <td>0.900500</td>\n      <td>0.900511</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.167100</td>\n      <td>0.242638</td>\n      <td>0.912500</td>\n      <td>0.912517</td>\n      <td>0.912500</td>\n      <td>0.912481</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.197100</td>\n      <td>0.241928</td>\n      <td>0.910000</td>\n      <td>0.910010</td>\n      <td>0.910000</td>\n      <td>0.909982</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.206600</td>\n      <td>0.242431</td>\n      <td>0.910000</td>\n      <td>0.910163</td>\n      <td>0.910000</td>\n      <td>0.909950</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:43]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 941.02 seconds\n\nRunning experiment with: Rank: 16, Target Matrices: ['attention.query', 'attention.key'], LoRA Dropout: 0.2\nModel has 11,748,100 total parameters\nModel has 62,978 trainable parameters\n0.54% of the parameters are trainable\nGPU memory allocated: 62.38 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 14:54, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.235800</td>\n      <td>0.240060</td>\n      <td>0.908000</td>\n      <td>0.908518</td>\n      <td>0.908000</td>\n      <td>0.908027</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.166400</td>\n      <td>0.245310</td>\n      <td>0.911000</td>\n      <td>0.911708</td>\n      <td>0.911000</td>\n      <td>0.911025</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.161400</td>\n      <td>0.241163</td>\n      <td>0.914000</td>\n      <td>0.914040</td>\n      <td>0.914000</td>\n      <td>0.913975</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.190800</td>\n      <td>0.240904</td>\n      <td>0.910000</td>\n      <td>0.910022</td>\n      <td>0.910000</td>\n      <td>0.909978</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.203500</td>\n      <td>0.241561</td>\n      <td>0.912500</td>\n      <td>0.912620</td>\n      <td>0.912500</td>\n      <td>0.912459</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:43]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 940.74 seconds\n\nRunning experiment with: Rank: 16, Target Matrices: ['attention.query', 'attention.key', 'attention.value'], LoRA Dropout: 0.1\nModel has 11,760,388 total parameters\nModel has 75,266 trainable parameters\n0.64% of the parameters are trainable\nGPU memory allocated: 62.47 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 14:54, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.583900</td>\n      <td>0.560658</td>\n      <td>0.729000</td>\n      <td>0.733980</td>\n      <td>0.729000</td>\n      <td>0.726332</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.301100</td>\n      <td>0.321680</td>\n      <td>0.867000</td>\n      <td>0.868315</td>\n      <td>0.867000</td>\n      <td>0.867025</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.244800</td>\n      <td>0.274331</td>\n      <td>0.894000</td>\n      <td>0.894043</td>\n      <td>0.894000</td>\n      <td>0.893964</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.274300</td>\n      <td>0.264743</td>\n      <td>0.895500</td>\n      <td>0.895521</td>\n      <td>0.895500</td>\n      <td>0.895472</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.254600</td>\n      <td>0.261431</td>\n      <td>0.896500</td>\n      <td>0.896521</td>\n      <td>0.896500</td>\n      <td>0.896473</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:43]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 940.95 seconds\n\nRunning experiment with: Rank: 16, Target Matrices: ['attention.query', 'attention.key', 'attention.value'], LoRA Dropout: 0.2\nModel has 11,760,388 total parameters\nModel has 75,266 trainable parameters\n0.64% of the parameters are trainable\nGPU memory allocated: 62.61 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 14:54, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.594100</td>\n      <td>0.573172</td>\n      <td>0.712000</td>\n      <td>0.717945</td>\n      <td>0.712000</td>\n      <td>0.708477</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.324400</td>\n      <td>0.329228</td>\n      <td>0.868000</td>\n      <td>0.868702</td>\n      <td>0.868000</td>\n      <td>0.868038</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.255500</td>\n      <td>0.280044</td>\n      <td>0.890000</td>\n      <td>0.890081</td>\n      <td>0.890000</td>\n      <td>0.889952</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.282300</td>\n      <td>0.269371</td>\n      <td>0.895500</td>\n      <td>0.895536</td>\n      <td>0.895500</td>\n      <td>0.895467</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.259500</td>\n      <td>0.265250</td>\n      <td>0.896500</td>\n      <td>0.896500</td>\n      <td>0.896500</td>\n      <td>0.896482</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:43]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 940.79 seconds\ntime: 3h 5min 59s (started: 2025-01-06 11:09:23 +00:00)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Testing evaluations saved\nresults_df_phase_2 = pd.DataFrame(results_phase_2)\nresults_df_phase_2.to_csv(\"7_FT_ALBERT_Experiments_FixedTrainingHyp.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T14:17:28.197970Z","iopub.execute_input":"2025-01-06T14:17:28.198346Z","iopub.status.idle":"2025-01-06T14:17:28.214300Z","shell.execute_reply.started":"2025-01-06T14:17:28.198316Z","shell.execute_reply":"2025-01-06T14:17:28.213534Z"}},"outputs":[{"name":"stdout","text":"time: 12.3 ms (started: 2025-01-06 14:17:28 +00:00)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}