{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"72b653b2a5a64ac09646dd9f9f943801":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ca31cf00f33e431086a1fd840c1ec1a1","IPY_MODEL_f974d40852674a6aa7256b2f19927aa9","IPY_MODEL_40b1e622f9e147c3af595ba4633645e5"],"layout":"IPY_MODEL_93e3912e1e724d01b1dc2c3458c5ba0e"}},"ca31cf00f33e431086a1fd840c1ec1a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9aebfd8aebe44d61a77b65c8bed284aa","placeholder":"​","style":"IPY_MODEL_376e5ecac0294510a1ec2337e033beb6","value":"Map: 100%"}},"f974d40852674a6aa7256b2f19927aa9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_db9d8a09fa6643828bfa844d3380f7f3","max":8000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3ed81ff6ee3e4e048e3dd4bfb997d05c","value":8000}},"40b1e622f9e147c3af595ba4633645e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_881c6fe2b0dd40e1a75d99a57b70e450","placeholder":"​","style":"IPY_MODEL_29e25dd314714fcabe51b3359c64f14d","value":" 8000/8000 [00:07&lt;00:00, 1109.45 examples/s]"}},"93e3912e1e724d01b1dc2c3458c5ba0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9aebfd8aebe44d61a77b65c8bed284aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"376e5ecac0294510a1ec2337e033beb6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db9d8a09fa6643828bfa844d3380f7f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ed81ff6ee3e4e048e3dd4bfb997d05c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"881c6fe2b0dd40e1a75d99a57b70e450":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29e25dd314714fcabe51b3359c64f14d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2300846a42cf4320a2334fac6e8d1276":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e1b3c6a68897456dbf2873d7cb598d08","IPY_MODEL_3f231b796633421688e36c165fb0b75b","IPY_MODEL_1467532e119942039d423945d7ba3724"],"layout":"IPY_MODEL_a9dc10ca26b248c3a19d6ececba46f11"}},"e1b3c6a68897456dbf2873d7cb598d08":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75d6b430c08b430dbd43e0a5ea595ebb","placeholder":"​","style":"IPY_MODEL_e776bc85300a4302a5378f8cb5671b19","value":"Map: 100%"}},"3f231b796633421688e36c165fb0b75b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_af867fa5cf5649b1a765a6281d73b160","max":2000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a669ca1a25434ddd9d2a720037693def","value":2000}},"1467532e119942039d423945d7ba3724":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_522bc4aa551e4a43bb6d2bae098d6e21","placeholder":"​","style":"IPY_MODEL_f40e896126d14009a71dd837ef147c53","value":" 2000/2000 [00:01&lt;00:00, 1151.43 examples/s]"}},"a9dc10ca26b248c3a19d6ececba46f11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75d6b430c08b430dbd43e0a5ea595ebb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e776bc85300a4302a5378f8cb5671b19":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af867fa5cf5649b1a765a6281d73b160":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a669ca1a25434ddd9d2a720037693def":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"522bc4aa551e4a43bb6d2bae098d6e21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f40e896126d14009a71dd837ef147c53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c7f8deb78954a4d9b78f3e661db65d8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_de3e29ce5ec64d0f88a5963a50466564","IPY_MODEL_b04c36eca0d6487f8d06f6fd1d9bb084","IPY_MODEL_9b00eeb368074deea88dd431ab4e8c8e"],"layout":"IPY_MODEL_07e4167bf03c46a39e58e7667231d370"}},"de3e29ce5ec64d0f88a5963a50466564":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd58ae91d34843a3a3ed44643a72c277","placeholder":"​","style":"IPY_MODEL_cd15492c83424caab76c8f197774548b","value":"Map: 100%"}},"b04c36eca0d6487f8d06f6fd1d9bb084":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_813faf21b45d4ee7857a375d353acbda","max":5000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9e5ca873be1f48a39599c027a39453e8","value":5000}},"9b00eeb368074deea88dd431ab4e8c8e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcdecbfc46f94a669a7477c010dcb206","placeholder":"​","style":"IPY_MODEL_0f6a30ceea3a4c47a3bccc8787d0f73d","value":" 5000/5000 [00:06&lt;00:00, 752.12 examples/s]"}},"07e4167bf03c46a39e58e7667231d370":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd58ae91d34843a3a3ed44643a72c277":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd15492c83424caab76c8f197774548b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"813faf21b45d4ee7857a375d353acbda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e5ca873be1f48a39599c027a39453e8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bcdecbfc46f94a669a7477c010dcb206":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f6a30ceea3a4c47a3bccc8787d0f73d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10376906,"sourceType":"datasetVersion","datasetId":6427851}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### **Installing dependencies**","metadata":{"id":"lGx3k9oTN6dU"}},{"cell_type":"code","source":"!pip install ipython-autotime gdown evaluate accelerate bitsandbytes peft loralib huggingface_hub transformers peft","metadata":{"id":"iqrl56zeCrIp","colab":{"base_uri":"https://localhost:8080/"},"outputId":"eb99b496-f862-4887-a102-648ea49630b0","trusted":true,"execution":{"iopub.status.busy":"2025-01-05T20:28:45.319201Z","iopub.execute_input":"2025-01-05T20:28:45.319410Z","iopub.status.idle":"2025-01-05T20:28:53.956618Z","shell.execute_reply.started":"2025-01-05T20:28:45.319390Z","shell.execute_reply":"2025-01-05T20:28:53.955573Z"}},"outputs":[{"name":"stdout","text":"Collecting ipython-autotime\n  Downloading ipython_autotime-0.3.2-py2.py3-none-any.whl.metadata (1.4 kB)\nRequirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\nCollecting peft\n  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\nCollecting loralib\n  Downloading loralib-0.1.2-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.24.7)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\nRequirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipython-autotime) (7.34.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\nRequirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.5)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.4.1+cu121)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\nRequirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\nCollecting huggingface_hub\n  Downloading huggingface_hub-0.27.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.8.30)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\nRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (71.0.4)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.7.5)\nRequirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (5.7.1)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (3.0.47)\nRequirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (2.18.0)\nRequirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.9.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.11.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.4)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.13)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading ipython_autotime-0.3.2-py2.py3-none-any.whl (7.0 kB)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading peft-0.14.0-py3-none-any.whl (374 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading loralib-0.1.2-py3-none-any.whl (10 kB)\nDownloading huggingface_hub-0.27.0-py3-none-any.whl (450 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.5/450.5 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: loralib, huggingface_hub, ipython-autotime, bitsandbytes, peft, evaluate\n  Attempting uninstall: huggingface_hub\n    Found existing installation: huggingface-hub 0.24.7\n    Uninstalling huggingface-hub-0.24.7:\n      Successfully uninstalled huggingface-hub-0.24.7\nSuccessfully installed bitsandbytes-0.45.0 evaluate-0.4.3 huggingface_hub-0.27.0 ipython-autotime-0.3.2 loralib-0.1.2 peft-0.14.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"##### **Importing dependencies**","metadata":{"id":"JYV5TiU2zwQM"}},{"cell_type":"code","source":"%load_ext autotime\nimport pandas as pd\nimport numpy as np\nimport nltk\nimport os\nimport zipfile\nimport tarfile\nimport re\nimport gdown\nimport gzip\nimport shutil\nimport wandb\nimport time\nimport torch\nimport psutil\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, precision_recall_fscore_support\nfrom datasets import Dataset\n\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSeq2SeqLM,\n    AutoModelForCausalLM,\n    AutoModelForSequenceClassification,\n    DistilBertTokenizerFast,\n    DistilBertForSequenceClassification,\n    RobertaTokenizerFast, \n    RobertaForSequenceClassification,\n    GPT2TokenizerFast, \n    GPT2ForSequenceClassification,\n    GenerationConfig,\n    TrainingArguments,\n    Trainer,\n    pipeline,\n    BitsAndBytesConfig,\n    DataCollatorForSeq2Seq,\n    DataCollatorWithPadding,\n    AdamW,\n    get_scheduler\n)\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm import tqdm\nimport time\nimport evaluate\nfrom peft import (\n    LoraConfig,\n    get_peft_model,\n    TaskType,\n    PeftModel,\n    PeftConfig,\n)\nfrom huggingface_hub import login\nimport kagglehub\n\n# from nltk.corpus import stopwords\n# from nltk import word_tokenize\n# from nltk.stem import WordNetLemmatizer\n# from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\n# from sklearn.metrics import accuracy_score\n# from sklearn.naive_bayes import MultinomialNB\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.neighbors import KNeighborsClassifier\n# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n# from google.colab import files\n# from scipy.sparse import hstack\n# from gensim.models import Word2Vec\n\nimport warnings\n\n# Suppress specific warnings\nwarnings.filterwarnings(\"ignore\", message=\".*clean_up_tokenization_spaces.*\")\nwarnings.filterwarnings(\"ignore\", message=\"Some weights of DistilBertForSequenceClassification were not initialized.*\")\nwarnings.filterwarnings(\"ignore\", message=\".*evaluation_strategy.*\")\nwarnings.filterwarnings(\"ignore\", message=\".*gather along dimension 0.*\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s58Pnf7Lz0Q2","outputId":"2ea414ab-9e3c-406f-b2db-0df497fd7455","trusted":true,"execution":{"iopub.status.busy":"2025-01-05T20:28:58.529439Z","iopub.execute_input":"2025-01-05T20:28:58.529709Z","iopub.status.idle":"2025-01-05T20:29:14.903466Z","shell.execute_reply.started":"2025-01-05T20:28:58.529688Z","shell.execute_reply":"2025-01-05T20:29:14.902613Z"}},"outputs":[{"name":"stdout","text":"time: 16.4 s (started: 2025-01-05 20:28:58 +00:00)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Disable wandb Logging\nos.environ[\"WANDB_MODE\"] = \"disabled\"\nwandb.init()\n\n# Check for GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T20:29:19.645413Z","iopub.execute_input":"2025-01-05T20:29:19.646088Z","iopub.status.idle":"2025-01-05T20:29:25.433243Z","shell.execute_reply.started":"2025-01-05T20:29:19.646056Z","shell.execute_reply":"2025-01-05T20:29:25.432469Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\ntime: 5.78 s (started: 2025-01-05 20:29:19 +00:00)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"##### **Supporting functions**","metadata":{}},{"cell_type":"code","source":"def clean_review(review):\n    review = re.sub(r'<.*?>', '', review)\n    review = re.sub(r'http\\S+|www\\S+|https\\S+', '', review, flags=re.MULTILINE)\n    review = review.strip()\n    return review\n\ndef preprocess_function(examples):\n    inputs = tokenizer(examples[\"review\"], truncation=True, padding=True, max_length=512)\n    inputs[\"labels\"] = [1 if label.lower() == \"positive\" else 0 for label in examples[\"sentiment\"]]\n    return inputs\n\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    acc = accuracy_score(labels, preds)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T20:29:27.577334Z","iopub.execute_input":"2025-01-05T20:29:27.578167Z","iopub.status.idle":"2025-01-05T20:29:27.582959Z","shell.execute_reply.started":"2025-01-05T20:29:27.578134Z","shell.execute_reply":"2025-01-05T20:29:27.582120Z"}},"outputs":[{"name":"stdout","text":"time: 446 µs (started: 2025-01-05 20:29:27 +00:00)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"##### **Loading data**","metadata":{}},{"cell_type":"code","source":"train_df_full = pd.read_csv(\"/kaggle/input/imdb-dataset-3/train.csv\")\ntrain_df = train_df_full.sample(n=3000, random_state=42)\ntrain_df['review'] = train_df['review'].apply(clean_review)\ntrain_df.reset_index(drop=True, inplace=True)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"of1BQo9GbCkM","outputId":"78d1609f-f5f3-4a94-dca4-a9a0a585374a","trusted":true,"execution":{"iopub.status.busy":"2025-01-05T20:29:38.039036Z","iopub.execute_input":"2025-01-05T20:29:38.039444Z","iopub.status.idle":"2025-01-05T20:29:38.977182Z","shell.execute_reply.started":"2025-01-05T20:29:38.039410Z","shell.execute_reply":"2025-01-05T20:29:38.976295Z"}},"outputs":[{"name":"stdout","text":"time: 934 ms (started: 2025-01-05 20:29:38 +00:00)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"test_df_full = pd.read_csv(\"/kaggle/input/imdb-dataset-3/test.csv\")\ntest_df = test_df_full.sample(n=2000, random_state=42)\ntest_df['review'] = test_df['review'].apply(clean_review)\ntest_df.reset_index(drop=True, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T20:29:38.978331Z","iopub.execute_input":"2025-01-05T20:29:38.978632Z","iopub.status.idle":"2025-01-05T20:29:39.556310Z","shell.execute_reply.started":"2025-01-05T20:29:38.978611Z","shell.execute_reply":"2025-01-05T20:29:39.555519Z"}},"outputs":[{"name":"stdout","text":"time: 574 ms (started: 2025-01-05 20:29:38 +00:00)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from datasets import Dataset\n\ntrain_dataset = Dataset.from_pandas(train_df)\ntest_dataset = Dataset.from_pandas(test_df)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":131,"referenced_widgets":["72b653b2a5a64ac09646dd9f9f943801","ca31cf00f33e431086a1fd840c1ec1a1","f974d40852674a6aa7256b2f19927aa9","40b1e622f9e147c3af595ba4633645e5","93e3912e1e724d01b1dc2c3458c5ba0e","9aebfd8aebe44d61a77b65c8bed284aa","376e5ecac0294510a1ec2337e033beb6","db9d8a09fa6643828bfa844d3380f7f3","3ed81ff6ee3e4e048e3dd4bfb997d05c","881c6fe2b0dd40e1a75d99a57b70e450","29e25dd314714fcabe51b3359c64f14d","2300846a42cf4320a2334fac6e8d1276","e1b3c6a68897456dbf2873d7cb598d08","3f231b796633421688e36c165fb0b75b","1467532e119942039d423945d7ba3724","a9dc10ca26b248c3a19d6ececba46f11","75d6b430c08b430dbd43e0a5ea595ebb","e776bc85300a4302a5378f8cb5671b19","af867fa5cf5649b1a765a6281d73b160","a669ca1a25434ddd9d2a720037693def","522bc4aa551e4a43bb6d2bae098d6e21","f40e896126d14009a71dd837ef147c53","2c7f8deb78954a4d9b78f3e661db65d8","de3e29ce5ec64d0f88a5963a50466564","b04c36eca0d6487f8d06f6fd1d9bb084","9b00eeb368074deea88dd431ab4e8c8e","07e4167bf03c46a39e58e7667231d370","dd58ae91d34843a3a3ed44643a72c277","cd15492c83424caab76c8f197774548b","813faf21b45d4ee7857a375d353acbda","9e5ca873be1f48a39599c027a39453e8","bcdecbfc46f94a669a7477c010dcb206","0f6a30ceea3a4c47a3bccc8787d0f73d"]},"id":"Zw1uk2V9awQL","outputId":"a1432fba-5921-4ce3-9d4d-ef7346229dac","trusted":true,"execution":{"iopub.status.busy":"2025-01-05T20:29:43.940467Z","iopub.execute_input":"2025-01-05T20:29:43.940743Z","iopub.status.idle":"2025-01-05T20:29:44.012211Z","shell.execute_reply.started":"2025-01-05T20:29:43.940722Z","shell.execute_reply":"2025-01-05T20:29:44.011388Z"}},"outputs":[{"name":"stdout","text":"time: 68 ms (started: 2025-01-05 20:29:43 +00:00)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"### **Experimentations for DistilBERT - Phase 1:** keeping LoRA hyperparams fixed","metadata":{}},{"cell_type":"code","source":"model_checkpoint = \"distilbert-base-uncased\"\ntokenizer = DistilBertTokenizerFast.from_pretrained(model_checkpoint)\nmodel = DistilBertForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2).to(device)\n\ntokenized_train = train_dataset.map(preprocess_function, batched=True)\ntokenized_test = test_dataset.map(preprocess_function, batched=True)\n\n# Fixed LoRA parameters\nrank = 8 \ntarget_matrices = [\"attention.q_lin\", \"attention.k_lin\", \"attention.v_lin\"]\nlora_alpha = 16\nlora_dropout = 0.1\n\n# Changing hyperparams for batch size, epochs and learning rates\nbatch_sizes = [16, 32]\nepochs_list = [3, 5]\nlearning_rates = [3e-5, 1e-4]\n\ntraining_dropout = 0.1 # Fixed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T19:13:12.703420Z","iopub.execute_input":"2025-01-05T19:13:12.703698Z","iopub.status.idle":"2025-01-05T19:13:18.231120Z","shell.execute_reply.started":"2025-01-05T19:13:12.703677Z","shell.execute_reply":"2025-01-05T19:13:18.230231Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa7993bceb8145f49e913e59a9d5a468"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f94b1c6c5754012808523670c261cd3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65410d63c0264518854d166db9e2ba37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c434f3147bf426f8edb34aadbc3d476"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03899c507fc8473398bde6b982b90bbe"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33187b4f24644dfab5530143da664261"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a35e0fca01f48ec93b04e14d419007c"}},"metadata":{}},{"name":"stdout","text":"time: 5.52 s (started: 2025-01-05 19:13:12 +00:00)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"print(f\"Model is running on device: {model.device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T19:13:31.268264Z","iopub.execute_input":"2025-01-05T19:13:31.268579Z","iopub.status.idle":"2025-01-05T19:13:31.273362Z","shell.execute_reply.started":"2025-01-05T19:13:31.268553Z","shell.execute_reply":"2025-01-05T19:13:31.272670Z"}},"outputs":[{"name":"stdout","text":"Model is running on device: cuda:0\ntime: 689 µs (started: 2025-01-05 19:13:31 +00:00)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"results_phase_1 = []\n\nfor batch_size in batch_sizes:\n    for epochs in epochs_list:\n        for learning_rate in learning_rates:\n            lora_config = LoraConfig(\n                r=rank,\n                lora_alpha=lora_alpha,\n                target_modules=target_matrices,\n                lora_dropout=lora_dropout,\n                task_type=\"SEQ_CLS\"\n            )\n\n            model_with_lora = get_peft_model(model, lora_config)\n            \n            start_time = time.time()\n            print(f\"\\nRunning experiment with: Batch Size: {batch_size}, Epochs: {epochs}, Learning Rate: {learning_rate}\")\n\n            num_parameters = sum(p.numel() for p in model_with_lora.parameters())\n            trainable_parameters = sum(p.numel() for p in model_with_lora.parameters() if p.requires_grad)\n            trainable_percentage = (trainable_parameters / num_parameters) * 100\n            \n            print(f\"Model has {num_parameters:,} total parameters\")\n            print(f\"Model has {trainable_parameters:,} trainable parameters\")\n            print(f\"{trainable_percentage:.2f}% of the parameters are trainable\")\n\n            if torch.cuda.is_available():\n                torch.cuda.empty_cache()\n                gpu_memory = torch.cuda.memory_allocated() / 1024**2  # in MB\n                print(f\"GPU memory allocated: {gpu_memory:.2f} MB\")\n\n            wandb.config.update({\"model/num_parameters\": model.num_parameters()}, allow_val_change=True)\n\n            output_dir = f\"./results_phase1_r{rank}_alpha{lora_alpha}_drop{lora_dropout}_targets{'_'.join(target_matrices)}_bs{batch_size}_epochs{epochs}_lr{learning_rate}\"\n            training_args = TrainingArguments(\n                output_dir=output_dir,\n                evaluation_strategy=\"epoch\",\n                learning_rate=learning_rate,\n                per_device_train_batch_size=batch_size,\n                per_device_eval_batch_size=batch_size,\n                num_train_epochs=epochs,\n                weight_decay=0.01,\n                save_total_limit=1,\n                save_strategy=\"epoch\",\n                logging_dir=\"./logs\",\n                logging_steps=10,\n                load_best_model_at_end=True,\n            )\n\n            trainer = Trainer(\n                model=model_with_lora,\n                args=training_args,\n                train_dataset=tokenized_train,\n                eval_dataset=tokenized_test,\n                tokenizer=tokenizer,\n                compute_metrics=compute_metrics\n            )\n\n            trainer.train()\n            metrics = trainer.evaluate()\n\n            end_time = time.time()\n            elapsed_time = end_time - start_time\n            print(f\"Training time: {elapsed_time:.2f} seconds\")\n\n            results_phase_1.append({\n                \"Model\": \"DistilBERT\",\n                \"Batch Size\": batch_size,\n                \"Epochs\": epochs,\n                \"Learning Rate\": learning_rate,\n                \"Rank\": rank,\n                \"Alpha\": lora_alpha,\n                \"LoRA Dropout\": lora_dropout,\n                \"Target Matrices\": target_matrices,\n                \"Accuracy\": metrics[\"eval_accuracy\"],\n                \"Precision\": metrics[\"eval_precision\"],\n                \"Recall\": metrics[\"eval_recall\"],\n                \"F1-Score\": metrics[\"eval_f1\"]                \n            })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T19:19:12.744245Z","iopub.execute_input":"2025-01-05T19:19:12.744643Z","iopub.status.idle":"2025-01-05T20:12:19.856539Z","shell.execute_reply.started":"2025-01-05T19:19:12.744609Z","shell.execute_reply":"2025-01-05T20:12:19.855845Z"}},"outputs":[{"name":"stdout","text":"\nRunning experiment with: Batch Size: 16, Epochs: 3, Learning Rate: 3e-05\nModel has 67,768,324 total parameters\nModel has 813,314 trainable parameters\n1.20% of the parameters are trainable\nGPU memory allocated: 259.60 MB\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='282' max='282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [282/282 04:32, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.641800</td>\n      <td>0.617792</td>\n      <td>0.843000</td>\n      <td>0.844074</td>\n      <td>0.843000</td>\n      <td>0.842667</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.482900</td>\n      <td>0.463158</td>\n      <td>0.869000</td>\n      <td>0.871597</td>\n      <td>0.869000</td>\n      <td>0.868974</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.429400</td>\n      <td>0.388128</td>\n      <td>0.874000</td>\n      <td>0.874275</td>\n      <td>0.874000</td>\n      <td>0.874032</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:23]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 298.87 seconds\n\nRunning experiment with: Batch Size: 16, Epochs: 3, Learning Rate: 0.0001\nModel has 67,768,324 total parameters\nModel has 813,314 trainable parameters\n1.20% of the parameters are trainable\nGPU memory allocated: 285.60 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='282' max='282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [282/282 04:43, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.346600</td>\n      <td>0.298442</td>\n      <td>0.882500</td>\n      <td>0.882504</td>\n      <td>0.882500</td>\n      <td>0.882502</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.226500</td>\n      <td>0.277897</td>\n      <td>0.887500</td>\n      <td>0.888883</td>\n      <td>0.887500</td>\n      <td>0.887520</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.305500</td>\n      <td>0.272050</td>\n      <td>0.892000</td>\n      <td>0.892009</td>\n      <td>0.892000</td>\n      <td>0.892004</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:23]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 307.90 seconds\n\nRunning experiment with: Batch Size: 16, Epochs: 5, Learning Rate: 3e-05\nModel has 67,768,324 total parameters\nModel has 813,314 trainable parameters\n1.20% of the parameters are trainable\nGPU memory allocated: 285.60 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 07:52, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.635000</td>\n      <td>0.605621</td>\n      <td>0.837500</td>\n      <td>0.841721</td>\n      <td>0.837500</td>\n      <td>0.836588</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.378800</td>\n      <td>0.355241</td>\n      <td>0.871000</td>\n      <td>0.873994</td>\n      <td>0.871000</td>\n      <td>0.870957</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.355800</td>\n      <td>0.292646</td>\n      <td>0.884500</td>\n      <td>0.885108</td>\n      <td>0.884500</td>\n      <td>0.884533</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.317900</td>\n      <td>0.285892</td>\n      <td>0.884500</td>\n      <td>0.884529</td>\n      <td>0.884500</td>\n      <td>0.884509</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.310100</td>\n      <td>0.284144</td>\n      <td>0.886000</td>\n      <td>0.886077</td>\n      <td>0.886000</td>\n      <td>0.886017</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:22]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 497.15 seconds\n\nRunning experiment with: Batch Size: 16, Epochs: 5, Learning Rate: 0.0001\nModel has 67,768,324 total parameters\nModel has 813,314 trainable parameters\n1.20% of the parameters are trainable\nGPU memory allocated: 285.78 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 07:52, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.352300</td>\n      <td>0.300506</td>\n      <td>0.884000</td>\n      <td>0.884161</td>\n      <td>0.884000</td>\n      <td>0.884024</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.222700</td>\n      <td>0.282783</td>\n      <td>0.881000</td>\n      <td>0.884174</td>\n      <td>0.881000</td>\n      <td>0.880954</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.297600</td>\n      <td>0.264211</td>\n      <td>0.894500</td>\n      <td>0.894514</td>\n      <td>0.894500</td>\n      <td>0.894505</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.245400</td>\n      <td>0.263305</td>\n      <td>0.895000</td>\n      <td>0.895021</td>\n      <td>0.895000</td>\n      <td>0.895007</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.234600</td>\n      <td>0.261977</td>\n      <td>0.896500</td>\n      <td>0.896509</td>\n      <td>0.896500</td>\n      <td>0.896477</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:22]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 497.14 seconds\n\nRunning experiment with: Batch Size: 32, Epochs: 3, Learning Rate: 3e-05\nModel has 67,768,324 total parameters\nModel has 813,314 trainable parameters\n1.20% of the parameters are trainable\nGPU memory allocated: 285.78 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [141/141 04:37, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.676300</td>\n      <td>0.658989</td>\n      <td>0.793000</td>\n      <td>0.820340</td>\n      <td>0.793000</td>\n      <td>0.789788</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.642600</td>\n      <td>0.626192</td>\n      <td>0.834000</td>\n      <td>0.834231</td>\n      <td>0.834000</td>\n      <td>0.833844</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.624300</td>\n      <td>0.609905</td>\n      <td>0.836000</td>\n      <td>0.837727</td>\n      <td>0.836000</td>\n      <td>0.835512</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [32/32 00:22]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 303.18 seconds\n\nRunning experiment with: Batch Size: 32, Epochs: 3, Learning Rate: 0.0001\nModel has 67,768,324 total parameters\nModel has 813,314 trainable parameters\n1.20% of the parameters are trainable\nGPU memory allocated: 286.04 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [141/141 04:37, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.588400</td>\n      <td>0.468848</td>\n      <td>0.864000</td>\n      <td>0.865042</td>\n      <td>0.864000</td>\n      <td>0.863738</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.306700</td>\n      <td>0.294007</td>\n      <td>0.881000</td>\n      <td>0.881916</td>\n      <td>0.881000</td>\n      <td>0.881031</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.308000</td>\n      <td>0.289238</td>\n      <td>0.878000</td>\n      <td>0.879611</td>\n      <td>0.878000</td>\n      <td>0.878015</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [32/32 00:22]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 303.40 seconds\n\nRunning experiment with: Batch Size: 32, Epochs: 5, Learning Rate: 3e-05\nModel has 67,768,324 total parameters\nModel has 813,314 trainable parameters\n1.20% of the parameters are trainable\nGPU memory allocated: 285.41 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='235' max='235' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [235/235 07:44, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.674600</td>\n      <td>0.654924</td>\n      <td>0.799500</td>\n      <td>0.825537</td>\n      <td>0.799500</td>\n      <td>0.796616</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.621400</td>\n      <td>0.597676</td>\n      <td>0.837500</td>\n      <td>0.847535</td>\n      <td>0.837500</td>\n      <td>0.836869</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.546300</td>\n      <td>0.512181</td>\n      <td>0.852500</td>\n      <td>0.857261</td>\n      <td>0.852500</td>\n      <td>0.852335</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.488000</td>\n      <td>0.438719</td>\n      <td>0.869500</td>\n      <td>0.869718</td>\n      <td>0.869500</td>\n      <td>0.869530</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.437700</td>\n      <td>0.414774</td>\n      <td>0.872000</td>\n      <td>0.872199</td>\n      <td>0.872000</td>\n      <td>0.872029</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [32/32 00:22]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 489.58 seconds\n\nRunning experiment with: Batch Size: 32, Epochs: 5, Learning Rate: 0.0001\nModel has 67,768,324 total parameters\nModel has 813,314 trainable parameters\n1.20% of the parameters are trainable\nGPU memory allocated: 286.29 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='235' max='235' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [235/235 07:44, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.584700</td>\n      <td>0.450914</td>\n      <td>0.864000</td>\n      <td>0.865877</td>\n      <td>0.864000</td>\n      <td>0.863611</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.294900</td>\n      <td>0.287131</td>\n      <td>0.884000</td>\n      <td>0.884772</td>\n      <td>0.884000</td>\n      <td>0.884032</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.285600</td>\n      <td>0.273588</td>\n      <td>0.892000</td>\n      <td>0.892230</td>\n      <td>0.892000</td>\n      <td>0.892026</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.278300</td>\n      <td>0.274153</td>\n      <td>0.888000</td>\n      <td>0.888133</td>\n      <td>0.888000</td>\n      <td>0.887938</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.261700</td>\n      <td>0.268723</td>\n      <td>0.892500</td>\n      <td>0.892588</td>\n      <td>0.892500</td>\n      <td>0.892517</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [32/32 00:22]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 489.72 seconds\ntime: 53min 7s (started: 2025-01-05 19:19:12 +00:00)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Testing evaluations saved\nresults_df_phase_1 = pd.DataFrame(results_phase_1)\nresults_df_phase_1.to_csv(\"5_FT_DistilBERT_Experiments_FixedLoRA.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T20:13:30.305626Z","iopub.execute_input":"2025-01-05T20:13:30.305919Z","iopub.status.idle":"2025-01-05T20:13:30.315243Z","shell.execute_reply.started":"2025-01-05T20:13:30.305896Z","shell.execute_reply":"2025-01-05T20:13:30.314191Z"}},"outputs":[{"name":"stdout","text":"time: 5.66 ms (started: 2025-01-05 20:13:30 +00:00)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"### **Experimentations for DistilBERT - Phase 2:** changing LoRA hyperparameters","metadata":{}},{"cell_type":"code","source":"model_checkpoint = \"distilbert-base-uncased\"\ntokenizer = DistilBertTokenizerFast.from_pretrained(model_checkpoint)\nmodel = DistilBertForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2).to(device)\n\ntokenized_train = train_dataset.map(preprocess_function, batched=True)\ntokenized_test = test_dataset.map(preprocess_function, batched=True)\n\n# Fixed parameters for batch size and epochs, etc\nfixed_batch_size = 16\nfixed_epochs = 5\nfixed_learning_rate = 1e-4\ntraining_dropout = 0.1\n\n# LoRA parameter combinations\nranks = [8, 16]\ntarget_matrices_list = [[\"attention.q_lin\"], [\"attention.q_lin\", \"attention.k_lin\"], [\"attention.q_lin\", \"attention.k_lin\", \"attention.v_lin\"]]\nlora_alpha = 16\nlora_dropouts = [0.1, 0.2]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T20:30:07.355813Z","iopub.execute_input":"2025-01-05T20:30:07.356121Z","iopub.status.idle":"2025-01-05T20:30:13.048096Z","shell.execute_reply.started":"2025-01-05T20:30:07.356094Z","shell.execute_reply":"2025-01-05T20:30:13.047419Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49090e1d205f4a7dbae227cf6a208fb8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec78251d47384a6eab577f8bf9401a8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49823e2971ed48e4b055c05108f8e42b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"068856573fbf454aa4efc558fe9ca4e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c76196065045420ba7b9a3725baaa365"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc2e365e6da2451c857503f2617ee517"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5e5a2033c824487b3ee2db47c9a23df"}},"metadata":{}},{"name":"stdout","text":"time: 5.69 s (started: 2025-01-05 20:30:07 +00:00)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"results_phase_2 = []\n\nfor rank in ranks:\n    for target_matrices in target_matrices_list:\n        for lora_dropout in lora_dropouts:\n            lora_config = LoraConfig(\n                r=rank,\n                lora_alpha=lora_alpha,  # Fixed lora_alpha\n                target_modules=target_matrices,\n                lora_dropout=lora_dropout,\n                task_type=\"SEQ_CLS\"\n            )\n\n            model_with_lora = get_peft_model(model, lora_config)\n\n            start_time = time.time()\n            print(f\"\\nRunning experiment with: Rank: {rank}, Target Matrices: {target_matrices}, LoRA Dropout: {lora_dropout}\")\n\n            num_parameters = sum(p.numel() for p in model_with_lora.parameters())\n            trainable_parameters = sum(p.numel() for p in model_with_lora.parameters() if p.requires_grad)\n            trainable_percentage = (trainable_parameters / num_parameters) * 100\n            \n            print(f\"Model has {num_parameters:,} total parameters\")\n            print(f\"Model has {trainable_parameters:,} trainable parameters\")\n            print(f\"{trainable_percentage:.2f}% of the parameters are trainable\")\n\n            if torch.cuda.is_available():\n                torch.cuda.empty_cache()\n                gpu_memory = torch.cuda.memory_allocated() / 1024**2  # in MB\n                print(f\"GPU memory allocated: {gpu_memory:.2f} MB\")\n\n            wandb.config.update({\"model/num_parameters\": model.num_parameters()}, allow_val_change=True)\n\n            output_dir = f\"./results_phase2_r{rank}_alpha{lora_alpha}_drop{lora_dropout}_targets{'_'.join(target_matrices)}_bs{fixed_batch_size}_epochs{fixed_epochs}_lr{fixed_learning_rate}\"\n            training_args = TrainingArguments(\n                output_dir=output_dir,\n                evaluation_strategy=\"epoch\",\n                learning_rate=fixed_learning_rate,\n                per_device_train_batch_size=fixed_batch_size,\n                per_device_eval_batch_size=fixed_batch_size,\n                num_train_epochs=fixed_epochs,\n                weight_decay=0.01,\n                save_total_limit=1,\n                save_strategy=\"epoch\",\n                logging_dir=\"./logs\",\n                logging_steps=10,\n                load_best_model_at_end=True,\n            )\n\n            trainer = Trainer(\n                model=model_with_lora,\n                args=training_args,\n                train_dataset=tokenized_train,\n                eval_dataset=tokenized_test,\n                tokenizer=tokenizer,\n                compute_metrics=compute_metrics\n            )\n\n            trainer.train()\n            metrics = trainer.evaluate()\n\n            end_time = time.time()\n            elapsed_time = end_time - start_time\n            print(f\"Training time: {elapsed_time:.2f} seconds\")\n\n            results_phase_2.append({\n                \"Model\": \"DistilBERT\",\n                \"Batch Size\": fixed_batch_size,\n                \"Epochs\": fixed_epochs,\n                \"Learning Rate\": fixed_learning_rate,\n                \"Rank\": rank,\n                \"Alpha\": lora_alpha,  # Fixed alpha\n                \"LoRA Dropout\": lora_dropout,\n                \"Target Matrices\": target_matrices,\n                \"Accuracy\": metrics[\"eval_accuracy\"],\n                \"Precision\": metrics[\"eval_precision\"],\n                \"Recall\": metrics[\"eval_recall\"],\n                \"F1-Score\": metrics[\"eval_f1\"]\n            })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T20:30:18.980212Z","iopub.execute_input":"2025-01-05T20:30:18.980543Z","iopub.status.idle":"2025-01-05T22:07:05.130103Z","shell.execute_reply.started":"2025-01-05T20:30:18.980516Z","shell.execute_reply":"2025-01-05T22:07:05.129439Z"}},"outputs":[{"name":"stdout","text":"\nRunning experiment with: Rank: 8, Target Matrices: ['attention.q_lin'], LoRA Dropout: 0.1\nModel has 67,620,868 total parameters\nModel has 665,858 trainable parameters\n0.98% of the parameters are trainable\nGPU memory allocated: 259.04 MB\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 07:09, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.494000</td>\n      <td>0.428150</td>\n      <td>0.845000</td>\n      <td>0.849940</td>\n      <td>0.845000</td>\n      <td>0.844044</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.229700</td>\n      <td>0.279210</td>\n      <td>0.887500</td>\n      <td>0.890226</td>\n      <td>0.887500</td>\n      <td>0.887476</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.311600</td>\n      <td>0.275927</td>\n      <td>0.894000</td>\n      <td>0.895165</td>\n      <td>0.894000</td>\n      <td>0.894024</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.271400</td>\n      <td>0.274655</td>\n      <td>0.892500</td>\n      <td>0.892545</td>\n      <td>0.892500</td>\n      <td>0.892511</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.261800</td>\n      <td>0.273740</td>\n      <td>0.891000</td>\n      <td>0.891101</td>\n      <td>0.891000</td>\n      <td>0.891018</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:21]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 454.02 seconds\n\nRunning experiment with: Rank: 8, Target Matrices: ['attention.q_lin'], LoRA Dropout: 0.2\nModel has 67,620,868 total parameters\nModel has 665,858 trainable parameters\n0.98% of the parameters are trainable\nGPU memory allocated: 282.91 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 07:23, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.499000</td>\n      <td>0.435013</td>\n      <td>0.844000</td>\n      <td>0.849444</td>\n      <td>0.844000</td>\n      <td>0.842960</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.231300</td>\n      <td>0.280165</td>\n      <td>0.887500</td>\n      <td>0.889971</td>\n      <td>0.887500</td>\n      <td>0.887485</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.308300</td>\n      <td>0.276426</td>\n      <td>0.894000</td>\n      <td>0.895081</td>\n      <td>0.894000</td>\n      <td>0.894025</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.272900</td>\n      <td>0.275097</td>\n      <td>0.893000</td>\n      <td>0.893021</td>\n      <td>0.893000</td>\n      <td>0.893007</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.263500</td>\n      <td>0.274169</td>\n      <td>0.891500</td>\n      <td>0.891565</td>\n      <td>0.891500</td>\n      <td>0.891514</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:21]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 467.03 seconds\n\nRunning experiment with: Rank: 8, Target Matrices: ['attention.q_lin', 'attention.k_lin'], LoRA Dropout: 0.1\nModel has 67,694,596 total parameters\nModel has 739,586 trainable parameters\n1.09% of the parameters are trainable\nGPU memory allocated: 283.82 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 07:35, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.444100</td>\n      <td>0.357172</td>\n      <td>0.870000</td>\n      <td>0.870645</td>\n      <td>0.870000</td>\n      <td>0.869818</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.217300</td>\n      <td>0.285500</td>\n      <td>0.890000</td>\n      <td>0.890774</td>\n      <td>0.890000</td>\n      <td>0.890031</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.273800</td>\n      <td>0.278292</td>\n      <td>0.894500</td>\n      <td>0.894990</td>\n      <td>0.894500</td>\n      <td>0.894530</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.248200</td>\n      <td>0.277880</td>\n      <td>0.892000</td>\n      <td>0.892012</td>\n      <td>0.892000</td>\n      <td>0.891974</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.249800</td>\n      <td>0.275829</td>\n      <td>0.893000</td>\n      <td>0.892992</td>\n      <td>0.893000</td>\n      <td>0.892988</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:22]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 479.16 seconds\n\nRunning experiment with: Rank: 8, Target Matrices: ['attention.q_lin', 'attention.k_lin'], LoRA Dropout: 0.2\nModel has 67,694,596 total parameters\nModel has 739,586 trainable parameters\n1.09% of the parameters are trainable\nGPU memory allocated: 284.66 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 07:36, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.446900</td>\n      <td>0.359739</td>\n      <td>0.869500</td>\n      <td>0.870174</td>\n      <td>0.869500</td>\n      <td>0.869312</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.216200</td>\n      <td>0.285174</td>\n      <td>0.892000</td>\n      <td>0.892846</td>\n      <td>0.892000</td>\n      <td>0.892029</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.277200</td>\n      <td>0.278282</td>\n      <td>0.895000</td>\n      <td>0.895463</td>\n      <td>0.895000</td>\n      <td>0.895030</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.253300</td>\n      <td>0.277743</td>\n      <td>0.891000</td>\n      <td>0.891012</td>\n      <td>0.891000</td>\n      <td>0.890974</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.251000</td>\n      <td>0.275947</td>\n      <td>0.891000</td>\n      <td>0.891002</td>\n      <td>0.891000</td>\n      <td>0.890979</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:22]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 480.66 seconds\n\nRunning experiment with: Rank: 8, Target Matrices: ['attention.q_lin', 'attention.k_lin', 'attention.v_lin'], LoRA Dropout: 0.1\nModel has 67,768,324 total parameters\nModel has 813,314 trainable parameters\n1.20% of the parameters are trainable\nGPU memory allocated: 284.94 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 07:45, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.357000</td>\n      <td>0.298979</td>\n      <td>0.883000</td>\n      <td>0.883022</td>\n      <td>0.883000</td>\n      <td>0.883007</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.217200</td>\n      <td>0.279719</td>\n      <td>0.885000</td>\n      <td>0.887652</td>\n      <td>0.885000</td>\n      <td>0.884978</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.295900</td>\n      <td>0.264674</td>\n      <td>0.895000</td>\n      <td>0.895054</td>\n      <td>0.895000</td>\n      <td>0.895013</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.245500</td>\n      <td>0.264079</td>\n      <td>0.896500</td>\n      <td>0.896504</td>\n      <td>0.896500</td>\n      <td>0.896502</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.235000</td>\n      <td>0.262653</td>\n      <td>0.897500</td>\n      <td>0.897501</td>\n      <td>0.897500</td>\n      <td>0.897482</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:22]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 489.69 seconds\n\nRunning experiment with: Rank: 8, Target Matrices: ['attention.q_lin', 'attention.k_lin', 'attention.v_lin'], LoRA Dropout: 0.2\nModel has 67,768,324 total parameters\nModel has 813,314 trainable parameters\n1.20% of the parameters are trainable\nGPU memory allocated: 285.78 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 07:45, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.360300</td>\n      <td>0.298756</td>\n      <td>0.883000</td>\n      <td>0.883009</td>\n      <td>0.883000</td>\n      <td>0.883004</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.216100</td>\n      <td>0.280613</td>\n      <td>0.885500</td>\n      <td>0.888219</td>\n      <td>0.885500</td>\n      <td>0.885475</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.298500</td>\n      <td>0.264825</td>\n      <td>0.894000</td>\n      <td>0.894054</td>\n      <td>0.894000</td>\n      <td>0.894013</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.247300</td>\n      <td>0.263963</td>\n      <td>0.896000</td>\n      <td>0.896020</td>\n      <td>0.896000</td>\n      <td>0.896007</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.237900</td>\n      <td>0.262672</td>\n      <td>0.896500</td>\n      <td>0.896495</td>\n      <td>0.896500</td>\n      <td>0.896486</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:22]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 489.57 seconds\n\nRunning experiment with: Rank: 16, Target Matrices: ['attention.q_lin'], LoRA Dropout: 0.1\nModel has 67,842,052 total parameters\nModel has 887,042 trainable parameters\n1.31% of the parameters are trainable\nGPU memory allocated: 285.50 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 07:46, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.294800</td>\n      <td>0.273457</td>\n      <td>0.893000</td>\n      <td>0.893100</td>\n      <td>0.893000</td>\n      <td>0.893018</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.189100</td>\n      <td>0.274529</td>\n      <td>0.888000</td>\n      <td>0.889729</td>\n      <td>0.888000</td>\n      <td>0.888010</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.268200</td>\n      <td>0.264465</td>\n      <td>0.897500</td>\n      <td>0.897734</td>\n      <td>0.897500</td>\n      <td>0.897428</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.214400</td>\n      <td>0.262977</td>\n      <td>0.897500</td>\n      <td>0.897537</td>\n      <td>0.897500</td>\n      <td>0.897468</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.212200</td>\n      <td>0.263420</td>\n      <td>0.897000</td>\n      <td>0.897178</td>\n      <td>0.897000</td>\n      <td>0.896937</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:22]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 490.31 seconds\n\nRunning experiment with: Rank: 16, Target Matrices: ['attention.q_lin'], LoRA Dropout: 0.2\nModel has 67,842,052 total parameters\nModel has 887,042 trainable parameters\n1.31% of the parameters are trainable\nGPU memory allocated: 286.35 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 07:46, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.273300</td>\n      <td>0.274624</td>\n      <td>0.900000</td>\n      <td>0.900031</td>\n      <td>0.900000</td>\n      <td>0.899971</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.171400</td>\n      <td>0.271528</td>\n      <td>0.896000</td>\n      <td>0.897001</td>\n      <td>0.896000</td>\n      <td>0.896026</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.240800</td>\n      <td>0.271992</td>\n      <td>0.896500</td>\n      <td>0.897358</td>\n      <td>0.896500</td>\n      <td>0.896342</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.187800</td>\n      <td>0.264806</td>\n      <td>0.904500</td>\n      <td>0.904708</td>\n      <td>0.904500</td>\n      <td>0.904439</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.194300</td>\n      <td>0.265618</td>\n      <td>0.905500</td>\n      <td>0.905749</td>\n      <td>0.905500</td>\n      <td>0.905433</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:22]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 490.72 seconds\n\nRunning experiment with: Rank: 16, Target Matrices: ['attention.q_lin', 'attention.k_lin'], LoRA Dropout: 0.1\nModel has 67,915,780 total parameters\nModel has 960,770 trainable parameters\n1.41% of the parameters are trainable\nGPU memory allocated: 286.91 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 07:47, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.268900</td>\n      <td>0.267425</td>\n      <td>0.891500</td>\n      <td>0.892309</td>\n      <td>0.891500</td>\n      <td>0.891530</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.182300</td>\n      <td>0.279032</td>\n      <td>0.890000</td>\n      <td>0.892176</td>\n      <td>0.890000</td>\n      <td>0.889996</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.269600</td>\n      <td>0.260321</td>\n      <td>0.898000</td>\n      <td>0.898009</td>\n      <td>0.898000</td>\n      <td>0.898003</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.204200</td>\n      <td>0.263646</td>\n      <td>0.900500</td>\n      <td>0.900502</td>\n      <td>0.900500</td>\n      <td>0.900483</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.196100</td>\n      <td>0.267671</td>\n      <td>0.903000</td>\n      <td>0.903406</td>\n      <td>0.903000</td>\n      <td>0.902909</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:22]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 491.24 seconds\n\nRunning experiment with: Rank: 16, Target Matrices: ['attention.q_lin', 'attention.k_lin'], LoRA Dropout: 0.2\nModel has 67,915,780 total parameters\nModel has 960,770 trainable parameters\n1.41% of the parameters are trainable\nGPU memory allocated: 287.75 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 07:46, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.248600</td>\n      <td>0.264657</td>\n      <td>0.899500</td>\n      <td>0.899511</td>\n      <td>0.899500</td>\n      <td>0.899478</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.184900</td>\n      <td>0.280248</td>\n      <td>0.892000</td>\n      <td>0.894065</td>\n      <td>0.892000</td>\n      <td>0.892000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.266200</td>\n      <td>0.259999</td>\n      <td>0.901000</td>\n      <td>0.901020</td>\n      <td>0.901000</td>\n      <td>0.901006</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.200900</td>\n      <td>0.266241</td>\n      <td>0.904000</td>\n      <td>0.904000</td>\n      <td>0.904000</td>\n      <td>0.903985</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.192800</td>\n      <td>0.270340</td>\n      <td>0.904000</td>\n      <td>0.904462</td>\n      <td>0.904000</td>\n      <td>0.903903</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:22]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 490.96 seconds\n\nRunning experiment with: Rank: 16, Target Matrices: ['attention.q_lin', 'attention.k_lin', 'attention.v_lin'], LoRA Dropout: 0.1\nModel has 67,989,508 total parameters\nModel has 1,034,498 trainable parameters\n1.52% of the parameters are trainable\nGPU memory allocated: 288.32 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 07:47, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.354800</td>\n      <td>0.298614</td>\n      <td>0.882000</td>\n      <td>0.881990</td>\n      <td>0.882000</td>\n      <td>0.881991</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.217100</td>\n      <td>0.284569</td>\n      <td>0.881500</td>\n      <td>0.885340</td>\n      <td>0.881500</td>\n      <td>0.881424</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.291900</td>\n      <td>0.262738</td>\n      <td>0.894500</td>\n      <td>0.894544</td>\n      <td>0.894500</td>\n      <td>0.894511</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.244700</td>\n      <td>0.261674</td>\n      <td>0.895000</td>\n      <td>0.894997</td>\n      <td>0.895000</td>\n      <td>0.894984</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.233600</td>\n      <td>0.260096</td>\n      <td>0.895500</td>\n      <td>0.895536</td>\n      <td>0.895500</td>\n      <td>0.895467</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:22]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 491.55 seconds\n\nRunning experiment with: Rank: 16, Target Matrices: ['attention.q_lin', 'attention.k_lin', 'attention.v_lin'], LoRA Dropout: 0.2\nModel has 67,989,508 total parameters\nModel has 1,034,498 trainable parameters\n1.52% of the parameters are trainable\nGPU memory allocated: 289.16 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 07:46, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.359500</td>\n      <td>0.298737</td>\n      <td>0.882000</td>\n      <td>0.881990</td>\n      <td>0.882000</td>\n      <td>0.881987</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.216000</td>\n      <td>0.284842</td>\n      <td>0.881000</td>\n      <td>0.885072</td>\n      <td>0.881000</td>\n      <td>0.880913</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.293400</td>\n      <td>0.262750</td>\n      <td>0.895000</td>\n      <td>0.895075</td>\n      <td>0.895000</td>\n      <td>0.895015</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.246300</td>\n      <td>0.261745</td>\n      <td>0.895000</td>\n      <td>0.895000</td>\n      <td>0.895000</td>\n      <td>0.895000</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.235900</td>\n      <td>0.260355</td>\n      <td>0.894500</td>\n      <td>0.894535</td>\n      <td>0.894500</td>\n      <td>0.894467</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:22]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 490.92 seconds\ntime: 1h 36min 46s (started: 2025-01-05 20:30:18 +00:00)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Testing evaluations saved\nresults_df_phase_2 = pd.DataFrame(results_phase_2)\nresults_df_phase_2.to_csv(\"5_FT_DistilBERT_Experiments_FixedTrainingHyp.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T22:15:32.197900Z","iopub.execute_input":"2025-01-05T22:15:32.198268Z","iopub.status.idle":"2025-01-05T22:15:32.207908Z","shell.execute_reply.started":"2025-01-05T22:15:32.198236Z","shell.execute_reply":"2025-01-05T22:15:32.207175Z"}},"outputs":[{"name":"stdout","text":"time: 6.25 ms (started: 2025-01-05 22:15:32 +00:00)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}