{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"72b653b2a5a64ac09646dd9f9f943801":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ca31cf00f33e431086a1fd840c1ec1a1","IPY_MODEL_f974d40852674a6aa7256b2f19927aa9","IPY_MODEL_40b1e622f9e147c3af595ba4633645e5"],"layout":"IPY_MODEL_93e3912e1e724d01b1dc2c3458c5ba0e"}},"ca31cf00f33e431086a1fd840c1ec1a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9aebfd8aebe44d61a77b65c8bed284aa","placeholder":"​","style":"IPY_MODEL_376e5ecac0294510a1ec2337e033beb6","value":"Map: 100%"}},"f974d40852674a6aa7256b2f19927aa9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_db9d8a09fa6643828bfa844d3380f7f3","max":8000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3ed81ff6ee3e4e048e3dd4bfb997d05c","value":8000}},"40b1e622f9e147c3af595ba4633645e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_881c6fe2b0dd40e1a75d99a57b70e450","placeholder":"​","style":"IPY_MODEL_29e25dd314714fcabe51b3359c64f14d","value":" 8000/8000 [00:07&lt;00:00, 1109.45 examples/s]"}},"93e3912e1e724d01b1dc2c3458c5ba0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9aebfd8aebe44d61a77b65c8bed284aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"376e5ecac0294510a1ec2337e033beb6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db9d8a09fa6643828bfa844d3380f7f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ed81ff6ee3e4e048e3dd4bfb997d05c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"881c6fe2b0dd40e1a75d99a57b70e450":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29e25dd314714fcabe51b3359c64f14d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2300846a42cf4320a2334fac6e8d1276":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e1b3c6a68897456dbf2873d7cb598d08","IPY_MODEL_3f231b796633421688e36c165fb0b75b","IPY_MODEL_1467532e119942039d423945d7ba3724"],"layout":"IPY_MODEL_a9dc10ca26b248c3a19d6ececba46f11"}},"e1b3c6a68897456dbf2873d7cb598d08":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75d6b430c08b430dbd43e0a5ea595ebb","placeholder":"​","style":"IPY_MODEL_e776bc85300a4302a5378f8cb5671b19","value":"Map: 100%"}},"3f231b796633421688e36c165fb0b75b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_af867fa5cf5649b1a765a6281d73b160","max":2000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a669ca1a25434ddd9d2a720037693def","value":2000}},"1467532e119942039d423945d7ba3724":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_522bc4aa551e4a43bb6d2bae098d6e21","placeholder":"​","style":"IPY_MODEL_f40e896126d14009a71dd837ef147c53","value":" 2000/2000 [00:01&lt;00:00, 1151.43 examples/s]"}},"a9dc10ca26b248c3a19d6ececba46f11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75d6b430c08b430dbd43e0a5ea595ebb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e776bc85300a4302a5378f8cb5671b19":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af867fa5cf5649b1a765a6281d73b160":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a669ca1a25434ddd9d2a720037693def":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"522bc4aa551e4a43bb6d2bae098d6e21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f40e896126d14009a71dd837ef147c53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c7f8deb78954a4d9b78f3e661db65d8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_de3e29ce5ec64d0f88a5963a50466564","IPY_MODEL_b04c36eca0d6487f8d06f6fd1d9bb084","IPY_MODEL_9b00eeb368074deea88dd431ab4e8c8e"],"layout":"IPY_MODEL_07e4167bf03c46a39e58e7667231d370"}},"de3e29ce5ec64d0f88a5963a50466564":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd58ae91d34843a3a3ed44643a72c277","placeholder":"​","style":"IPY_MODEL_cd15492c83424caab76c8f197774548b","value":"Map: 100%"}},"b04c36eca0d6487f8d06f6fd1d9bb084":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_813faf21b45d4ee7857a375d353acbda","max":5000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9e5ca873be1f48a39599c027a39453e8","value":5000}},"9b00eeb368074deea88dd431ab4e8c8e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcdecbfc46f94a669a7477c010dcb206","placeholder":"​","style":"IPY_MODEL_0f6a30ceea3a4c47a3bccc8787d0f73d","value":" 5000/5000 [00:06&lt;00:00, 752.12 examples/s]"}},"07e4167bf03c46a39e58e7667231d370":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd58ae91d34843a3a3ed44643a72c277":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd15492c83424caab76c8f197774548b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"813faf21b45d4ee7857a375d353acbda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e5ca873be1f48a39599c027a39453e8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bcdecbfc46f94a669a7477c010dcb206":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f6a30ceea3a4c47a3bccc8787d0f73d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10381688,"sourceType":"datasetVersion","datasetId":6431167}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### **Installing dependencies**","metadata":{"id":"lGx3k9oTN6dU"}},{"cell_type":"code","source":"!pip install ipython-autotime gdown evaluate accelerate bitsandbytes peft loralib huggingface_hub transformers peft","metadata":{"id":"iqrl56zeCrIp","colab":{"base_uri":"https://localhost:8080/"},"outputId":"eb99b496-f862-4887-a102-648ea49630b0","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### **Importing dependencies**","metadata":{"id":"JYV5TiU2zwQM"}},{"cell_type":"code","source":"%load_ext autotime\nimport pandas as pd\nimport numpy as np\nimport nltk\nimport os\nimport zipfile\nimport tarfile\nimport re\nimport gdown\nimport gzip\nimport shutil\nimport wandb\nimport time\nimport torch\nimport psutil\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, precision_recall_fscore_support\nfrom datasets import Dataset\n\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSeq2SeqLM,\n    AutoModelForCausalLM,\n    AutoModelForSequenceClassification,\n    DistilBertTokenizerFast,\n    DistilBertForSequenceClassification,\n    RobertaTokenizerFast, \n    RobertaForSequenceClassification,\n    GPT2TokenizerFast, \n    GPT2ForSequenceClassification,\n    AlbertTokenizer, \n    AlbertForSequenceClassification,\n    GenerationConfig,\n    TrainingArguments,\n    Trainer,\n    pipeline,\n    BitsAndBytesConfig,\n    DataCollatorForSeq2Seq,\n    DataCollatorWithPadding,\n    AdamW,\n    get_scheduler\n)\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm import tqdm\nimport time\nimport evaluate\nfrom peft import (\n    LoraConfig,\n    get_peft_model,\n    TaskType,\n    PeftModel,\n    PeftConfig,\n)\nfrom huggingface_hub import login\nimport kagglehub\n\n# from nltk.corpus import stopwords\n# from nltk import word_tokenize\n# from nltk.stem import WordNetLemmatizer\n# from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\n# from sklearn.metrics import accuracy_score\n# from sklearn.naive_bayes import MultinomialNB\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.neighbors import KNeighborsClassifier\n# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n# from google.colab import files\n# from scipy.sparse import hstack\n# from gensim.models import Word2Vec\n\nimport warnings\n\n# Suppress specific warnings\nwarnings.filterwarnings(\"ignore\", message=\".*clean_up_tokenization_spaces.*\")\nwarnings.filterwarnings(\"ignore\", message=\"Some weights of DistilBertForSequenceClassification were not initialized.*\")\nwarnings.filterwarnings(\"ignore\", message=\"Some weights of AlbertForSequenceClassification were not initialized.*\")\nwarnings.filterwarnings(\"ignore\", message=\".*evaluation_strategy.*\")\nwarnings.filterwarnings(\"ignore\", message=\".*gather along dimension 0.*\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s58Pnf7Lz0Q2","outputId":"2ea414ab-9e3c-406f-b2db-0df497fd7455","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Disable wandb Logging\nos.environ[\"WANDB_MODE\"] = \"disabled\"\nwandb.init()\n\n# Check for GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T02:19:58.559317Z","iopub.execute_input":"2025-01-06T02:19:58.559987Z","iopub.status.idle":"2025-01-06T02:20:04.458690Z","shell.execute_reply.started":"2025-01-06T02:19:58.559958Z","shell.execute_reply":"2025-01-06T02:20:04.457870Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\ntime: 5.9 s (started: 2025-01-06 02:19:58 +00:00)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"##### **Supporting functions**","metadata":{}},{"cell_type":"code","source":"def clean_review(review):\n    review = re.sub(r'<.*?>', '', review)\n    review = re.sub(r'http\\S+|www\\S+|https\\S+', '', review, flags=re.MULTILINE)\n    review = review.strip()\n    return review\n\ndef preprocess_function(examples):\n    inputs = tokenizer(examples[\"review\"], truncation=True, padding=True, max_length=512)\n    inputs[\"labels\"] = [1 if label.lower() == \"positive\" else 0 for label in examples[\"sentiment\"]]\n    return inputs\n\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    acc = accuracy_score(labels, preds)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T02:20:06.692945Z","iopub.execute_input":"2025-01-06T02:20:06.693808Z","iopub.status.idle":"2025-01-06T02:20:06.700543Z","shell.execute_reply.started":"2025-01-06T02:20:06.693770Z","shell.execute_reply":"2025-01-06T02:20:06.699644Z"}},"outputs":[{"name":"stdout","text":"time: 769 µs (started: 2025-01-06 02:20:06 +00:00)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"##### **Loading data**","metadata":{}},{"cell_type":"code","source":"train_df_full = pd.read_csv(\"/kaggle/input/imdb-dataset-3/train.csv\")\ntrain_df = train_df_full.sample(n=3000, random_state=42)\ntrain_df['review'] = train_df['review'].apply(clean_review)\ntrain_df.reset_index(drop=True, inplace=True)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"of1BQo9GbCkM","outputId":"78d1609f-f5f3-4a94-dca4-a9a0a585374a","trusted":true,"execution":{"iopub.status.busy":"2025-01-06T02:20:11.283178Z","iopub.execute_input":"2025-01-06T02:20:11.283455Z","iopub.status.idle":"2025-01-06T02:20:12.249988Z","shell.execute_reply.started":"2025-01-06T02:20:11.283433Z","shell.execute_reply":"2025-01-06T02:20:12.249063Z"}},"outputs":[{"name":"stdout","text":"time: 963 ms (started: 2025-01-06 02:20:11 +00:00)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"test_df_full = pd.read_csv(\"/kaggle/input/imdb-dataset-3/test.csv\")\ntest_df = test_df_full.sample(n=2000, random_state=42)\ntest_df['review'] = test_df['review'].apply(clean_review)\ntest_df.reset_index(drop=True, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T02:20:14.342346Z","iopub.execute_input":"2025-01-06T02:20:14.342645Z","iopub.status.idle":"2025-01-06T02:20:14.990183Z","shell.execute_reply.started":"2025-01-06T02:20:14.342619Z","shell.execute_reply":"2025-01-06T02:20:14.989162Z"}},"outputs":[{"name":"stdout","text":"time: 643 ms (started: 2025-01-06 02:20:14 +00:00)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from datasets import Dataset\n\ntrain_dataset = Dataset.from_pandas(train_df)\ntest_dataset = Dataset.from_pandas(test_df)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":131,"referenced_widgets":["72b653b2a5a64ac09646dd9f9f943801","ca31cf00f33e431086a1fd840c1ec1a1","f974d40852674a6aa7256b2f19927aa9","40b1e622f9e147c3af595ba4633645e5","93e3912e1e724d01b1dc2c3458c5ba0e","9aebfd8aebe44d61a77b65c8bed284aa","376e5ecac0294510a1ec2337e033beb6","db9d8a09fa6643828bfa844d3380f7f3","3ed81ff6ee3e4e048e3dd4bfb997d05c","881c6fe2b0dd40e1a75d99a57b70e450","29e25dd314714fcabe51b3359c64f14d","2300846a42cf4320a2334fac6e8d1276","e1b3c6a68897456dbf2873d7cb598d08","3f231b796633421688e36c165fb0b75b","1467532e119942039d423945d7ba3724","a9dc10ca26b248c3a19d6ececba46f11","75d6b430c08b430dbd43e0a5ea595ebb","e776bc85300a4302a5378f8cb5671b19","af867fa5cf5649b1a765a6281d73b160","a669ca1a25434ddd9d2a720037693def","522bc4aa551e4a43bb6d2bae098d6e21","f40e896126d14009a71dd837ef147c53","2c7f8deb78954a4d9b78f3e661db65d8","de3e29ce5ec64d0f88a5963a50466564","b04c36eca0d6487f8d06f6fd1d9bb084","9b00eeb368074deea88dd431ab4e8c8e","07e4167bf03c46a39e58e7667231d370","dd58ae91d34843a3a3ed44643a72c277","cd15492c83424caab76c8f197774548b","813faf21b45d4ee7857a375d353acbda","9e5ca873be1f48a39599c027a39453e8","bcdecbfc46f94a669a7477c010dcb206","0f6a30ceea3a4c47a3bccc8787d0f73d"]},"id":"Zw1uk2V9awQL","outputId":"a1432fba-5921-4ce3-9d4d-ef7346229dac","trusted":true,"execution":{"iopub.status.busy":"2025-01-06T02:20:18.746474Z","iopub.execute_input":"2025-01-06T02:20:18.746800Z","iopub.status.idle":"2025-01-06T02:20:18.820719Z","shell.execute_reply.started":"2025-01-06T02:20:18.746774Z","shell.execute_reply":"2025-01-06T02:20:18.819791Z"}},"outputs":[{"name":"stdout","text":"time: 70.2 ms (started: 2025-01-06 02:20:18 +00:00)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"### **Experimentations for ALBERT - Phase 1:** keeping LoRA hyperparams fixed","metadata":{}},{"cell_type":"code","source":"model_checkpoint = \"albert-base-v2\"\ntokenizer = AlbertTokenizer.from_pretrained(model_checkpoint)\nmodel = AlbertForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2).to(device)\n\ntokenized_train = train_dataset.map(preprocess_function, batched=True)\ntokenized_test = test_dataset.map(preprocess_function, batched=True)\n\n# Fixed LoRA parameters\nrank = 8 \ntarget_matrices = [\"attention.query\", \"attention.key\", \"attention.value\"]\nlora_alpha = 16\nlora_dropout = 0.1\n\n# Changing hyperparams for batch size, epochs and learning rates\nbatch_sizes = [4, 8]\nepochs_list = [3, 5]\nlearning_rates = [3e-5, 1e-4]\n\ntraining_dropout = 0.1 # Fixed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T02:20:26.924076Z","iopub.execute_input":"2025-01-06T02:20:26.924359Z","iopub.status.idle":"2025-01-06T02:20:40.738242Z","shell.execute_reply.started":"2025-01-06T02:20:26.924338Z","shell.execute_reply":"2025-01-06T02:20:40.737539Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"895fb908af594febbc22e73c62cd5786"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"282494bc17fd48b4b17810a50304c4d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b84af4edfd44415b2316668887741da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"399dc107abef4b19a3bf853ece2a3681"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/47.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2cbd43540d14edbae453e4369f1ce83"}},"metadata":{}},{"name":"stderr","text":"Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"553699ba0d3c4ece947f65d56dca1b0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e08e8129e0984c418436553e38488a6a"}},"metadata":{}},{"name":"stdout","text":"time: 13.8 s (started: 2025-01-06 02:20:26 +00:00)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"print(f\"Model is running on device: {model.device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T02:20:43.638788Z","iopub.execute_input":"2025-01-06T02:20:43.639079Z","iopub.status.idle":"2025-01-06T02:20:43.643921Z","shell.execute_reply.started":"2025-01-06T02:20:43.639058Z","shell.execute_reply":"2025-01-06T02:20:43.643085Z"}},"outputs":[{"name":"stdout","text":"Model is running on device: cuda:0\ntime: 518 µs (started: 2025-01-06 02:20:43 +00:00)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"results_phase_1 = []\n\nfor batch_size in batch_sizes:\n    for epochs in epochs_list:\n        for learning_rate in learning_rates:\n            lora_config = LoraConfig(\n                r=rank,\n                lora_alpha=lora_alpha,\n                target_modules=target_matrices,\n                lora_dropout=lora_dropout,\n                task_type=\"SEQ_CLS\"\n            )\n\n            model_with_lora = get_peft_model(model, lora_config)\n            \n            start_time = time.time()\n            print(f\"\\nRunning experiment with: Batch Size: {batch_size}, Epochs: {epochs}, Learning Rate: {learning_rate}\")\n\n            num_parameters = sum(p.numel() for p in model_with_lora.parameters())\n            trainable_parameters = sum(p.numel() for p in model_with_lora.parameters() if p.requires_grad)\n            trainable_percentage = (trainable_parameters / num_parameters) * 100\n            \n            print(f\"Model has {num_parameters:,} total parameters\")\n            print(f\"Model has {trainable_parameters:,} trainable parameters\")\n            print(f\"{trainable_percentage:.2f}% of the parameters are trainable\")\n\n            if torch.cuda.is_available():\n                torch.cuda.empty_cache()\n                gpu_memory = torch.cuda.memory_allocated() / 1024**2  # in MB\n                print(f\"GPU memory allocated: {gpu_memory:.2f} MB\")\n\n            wandb.config.update({\"model/num_parameters\": model.num_parameters()}, allow_val_change=True)\n\n            output_dir = f\"./results_phase1_r{rank}_alpha{lora_alpha}_drop{lora_dropout}_targets{'_'.join(target_matrices)}_bs{batch_size}_epochs{epochs}_lr{learning_rate}\"\n            training_args = TrainingArguments(\n                output_dir=output_dir,\n                evaluation_strategy=\"epoch\",\n                learning_rate=learning_rate,\n                per_device_train_batch_size=batch_size,\n                per_device_eval_batch_size=batch_size,\n                num_train_epochs=epochs,\n                weight_decay=0.01,\n                save_total_limit=1,\n                save_strategy=\"epoch\",\n                logging_dir=\"./logs\",\n                logging_steps=10,\n                load_best_model_at_end=True,\n            )\n\n            trainer = Trainer(\n                model=model_with_lora,\n                args=training_args,\n                train_dataset=tokenized_train,\n                eval_dataset=tokenized_test,\n                tokenizer=tokenizer,\n                compute_metrics=compute_metrics\n            )\n\n            trainer.train()\n            metrics = trainer.evaluate()\n\n            end_time = time.time()\n            elapsed_time = end_time - start_time\n            print(f\"Training time: {elapsed_time:.2f} seconds\")\n\n            results_phase_1.append({\n                \"Model\": \"ALBERT\",\n                \"Batch Size\": batch_size,\n                \"Epochs\": epochs,\n                \"Learning Rate\": learning_rate,\n                \"Rank\": rank,\n                \"Alpha\": lora_alpha,\n                \"LoRA Dropout\": lora_dropout,\n                \"Target Matrices\": target_matrices,\n                \"Accuracy\": metrics[\"eval_accuracy\"],\n                \"Precision\": metrics[\"eval_precision\"],\n                \"Recall\": metrics[\"eval_recall\"],\n                \"F1-Score\": metrics[\"eval_f1\"]                \n            })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T02:20:44.872256Z","iopub.execute_input":"2025-01-06T02:20:44.872611Z","iopub.status.idle":"2025-01-06T03:15:24.037717Z","shell.execute_reply.started":"2025-01-06T02:20:44.872584Z","shell.execute_reply":"2025-01-06T03:15:24.036215Z"}},"outputs":[{"name":"stdout","text":"\nRunning experiment with: Batch Size: 16, Epochs: 3, Learning Rate: 3e-05\nModel has 11,723,524 total parameters\nModel has 38,402 trainable parameters\n0.33% of the parameters are trainable\nGPU memory allocated: 44.73 MB\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='282' max='282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [282/282 09:24, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.682400</td>\n      <td>0.690203</td>\n      <td>0.522500</td>\n      <td>0.522046</td>\n      <td>0.522500</td>\n      <td>0.522163</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.693600</td>\n      <td>0.679840</td>\n      <td>0.576000</td>\n      <td>0.576184</td>\n      <td>0.576000</td>\n      <td>0.576071</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.684700</td>\n      <td>0.674141</td>\n      <td>0.586000</td>\n      <td>0.586750</td>\n      <td>0.586000</td>\n      <td>0.580149</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:47]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 616.59 seconds\n\nRunning experiment with: Batch Size: 16, Epochs: 3, Learning Rate: 0.0001\nModel has 11,723,524 total parameters\nModel has 38,402 trainable parameters\n0.33% of the parameters are trainable\nGPU memory allocated: 62.05 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='282' max='282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [282/282 09:38, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.646300</td>\n      <td>0.649045</td>\n      <td>0.623500</td>\n      <td>0.666646</td>\n      <td>0.623500</td>\n      <td>0.589580</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.529600</td>\n      <td>0.518256</td>\n      <td>0.803500</td>\n      <td>0.807859</td>\n      <td>0.803500</td>\n      <td>0.803280</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.428800</td>\n      <td>0.430748</td>\n      <td>0.842000</td>\n      <td>0.842068</td>\n      <td>0.842000</td>\n      <td>0.841913</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:47]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 629.46 seconds\n\nRunning experiment with: Batch Size: 16, Epochs: 5, Learning Rate: 3e-05\nModel has 11,723,524 total parameters\nModel has 38,402 trainable parameters\n0.33% of the parameters are trainable\nGPU memory allocated: 62.05 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 16:04, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.682100</td>\n      <td>0.688815</td>\n      <td>0.524000</td>\n      <td>0.523218</td>\n      <td>0.524000</td>\n      <td>0.523255</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.686400</td>\n      <td>0.674546</td>\n      <td>0.601000</td>\n      <td>0.607490</td>\n      <td>0.601000</td>\n      <td>0.598616</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.662100</td>\n      <td>0.657121</td>\n      <td>0.660500</td>\n      <td>0.669557</td>\n      <td>0.660500</td>\n      <td>0.658221</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.649100</td>\n      <td>0.641224</td>\n      <td>0.683500</td>\n      <td>0.684145</td>\n      <td>0.683500</td>\n      <td>0.682267</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.638300</td>\n      <td>0.636038</td>\n      <td>0.693000</td>\n      <td>0.693585</td>\n      <td>0.693000</td>\n      <td>0.691940</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:47]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 1015.05 seconds\n\nRunning experiment with: Batch Size: 16, Epochs: 5, Learning Rate: 0.0001\nModel has 11,723,524 total parameters\nModel has 38,402 trainable parameters\n0.33% of the parameters are trainable\nGPU memory allocated: 62.05 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 16:04, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.638100</td>\n      <td>0.633368</td>\n      <td>0.672500</td>\n      <td>0.707261</td>\n      <td>0.672500</td>\n      <td>0.653722</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.430800</td>\n      <td>0.410343</td>\n      <td>0.851500</td>\n      <td>0.851488</td>\n      <td>0.851500</td>\n      <td>0.851492</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.312200</td>\n      <td>0.321190</td>\n      <td>0.878000</td>\n      <td>0.882043</td>\n      <td>0.878000</td>\n      <td>0.877416</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.282000</td>\n      <td>0.285743</td>\n      <td>0.893000</td>\n      <td>0.893140</td>\n      <td>0.893000</td>\n      <td>0.892941</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.322600</td>\n      <td>0.279729</td>\n      <td>0.895500</td>\n      <td>0.896281</td>\n      <td>0.895500</td>\n      <td>0.895350</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:47]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 1015.84 seconds\n\nRunning experiment with: Batch Size: 32, Epochs: 3, Learning Rate: 3e-05\nModel has 11,723,524 total parameters\nModel has 38,402 trainable parameters\n0.33% of the parameters are trainable\nGPU memory allocated: 62.05 MB\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-fcbbc40cd062>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m             )\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1937\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1938\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1939\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1940\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2278\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2279\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2281\u001b[0m                 if (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3317\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3318\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3320\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3361\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: Caught OutOfMemoryError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/parallel_apply.py\", line 84, in _worker\n    output = module(*input, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\", line 1521, in forward\n    return self.base_model(\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py\", line 197, in forward\n    return self.model.forward(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/albert/modeling_albert.py\", line 1059, in forward\n    outputs = self.albert(\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/albert/modeling_albert.py\", line 719, in forward\n    encoder_outputs = self.encoder(\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/albert/modeling_albert.py\", line 468, in forward\n    layer_group_output = self.albert_layer_groups[group_idx](\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/albert/modeling_albert.py\", line 420, in forward\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/albert/modeling_albert.py\", line 383, in forward\n    attention_output = self.attention(hidden_states, attention_mask, head_mask, output_attentions)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/albert/modeling_albert.py\", line 318, in forward\n    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 164.12 MiB is free. Process 2475 has 14.58 GiB memory in use. Of the allocated memory 14.32 GiB is allocated by PyTorch, and 60.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"],"ename":"OutOfMemoryError","evalue":"Caught OutOfMemoryError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/parallel_apply.py\", line 84, in _worker\n    output = module(*input, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\", line 1521, in forward\n    return self.base_model(\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py\", line 197, in forward\n    return self.model.forward(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/albert/modeling_albert.py\", line 1059, in forward\n    outputs = self.albert(\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/albert/modeling_albert.py\", line 719, in forward\n    encoder_outputs = self.encoder(\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/albert/modeling_albert.py\", line 468, in forward\n    layer_group_output = self.albert_layer_groups[group_idx](\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/albert/modeling_albert.py\", line 420, in forward\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/albert/modeling_albert.py\", line 383, in forward\n    attention_output = self.attention(hidden_states, attention_mask, head_mask, output_attentions)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/albert/modeling_albert.py\", line 318, in forward\n    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 164.12 MiB is free. Process 2475 has 14.58 GiB memory in use. Of the allocated memory 14.32 GiB is allocated by PyTorch, and 60.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"error"},{"name":"stdout","text":"time: 54min 39s (started: 2025-01-06 02:20:44 +00:00)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Testing evaluations saved\nresults_df_phase_1 = pd.DataFrame(results_phase_1)\nresults_df_phase_1.to_csv(\"7_FT_ALBERT_Experiments_FixedLoRA.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T20:13:30.305626Z","iopub.execute_input":"2025-01-05T20:13:30.305919Z","iopub.status.idle":"2025-01-05T20:13:30.315243Z","shell.execute_reply.started":"2025-01-05T20:13:30.305896Z","shell.execute_reply":"2025-01-05T20:13:30.314191Z"}},"outputs":[{"name":"stdout","text":"time: 5.66 ms (started: 2025-01-05 20:13:30 +00:00)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"### **Experimentations for ALBERT - Phase 2:** changing LoRA hyperparameters","metadata":{}},{"cell_type":"code","source":"model_checkpoint = \"albert-base-v2\"\ntokenizer = AlbertTokenizer.from_pretrained(model_checkpoint)\nmodel = AlbertForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2).to(device)\n\ntokenized_train = train_dataset.map(preprocess_function, batched=True)\ntokenized_test = test_dataset.map(preprocess_function, batched=True)\n\n# Fixed parameters for batch size and epochs, etc\nfixed_batch_size = 16\nfixed_epochs = 5\nfixed_learning_rate = 1e-4\ntraining_dropout = 0.1\n\n# LoRA parameter combinations\nranks = [8, 16]\ntarget_matrices_list = [[\"attention.query\"], [\"attention.query\", \"attention.key\"], [\"attention.query\", \"attention.key\", \"attention.value\"]]\nlora_alpha = 16\nlora_dropouts = [0.1, 0.2]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T20:30:07.355813Z","iopub.execute_input":"2025-01-05T20:30:07.356121Z","iopub.status.idle":"2025-01-05T20:30:13.048096Z","shell.execute_reply.started":"2025-01-05T20:30:07.356094Z","shell.execute_reply":"2025-01-05T20:30:13.047419Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49090e1d205f4a7dbae227cf6a208fb8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec78251d47384a6eab577f8bf9401a8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49823e2971ed48e4b055c05108f8e42b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"068856573fbf454aa4efc558fe9ca4e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c76196065045420ba7b9a3725baaa365"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc2e365e6da2451c857503f2617ee517"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5e5a2033c824487b3ee2db47c9a23df"}},"metadata":{}},{"name":"stdout","text":"time: 5.69 s (started: 2025-01-05 20:30:07 +00:00)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"results_phase_2 = []\n\nfor rank in ranks:\n    for target_matrices in target_matrices_list:\n        for lora_dropout in lora_dropouts:\n            lora_config = LoraConfig(\n                r=rank,\n                lora_alpha=lora_alpha,  # Fixed lora_alpha\n                target_modules=target_matrices,\n                lora_dropout=lora_dropout,\n                task_type=\"SEQ_CLS\"\n            )\n\n            model_with_lora = get_peft_model(model, lora_config)\n\n            start_time = time.time()\n            print(f\"\\nRunning experiment with: Rank: {rank}, Target Matrices: {target_matrices}, LoRA Dropout: {lora_dropout}\")\n\n            num_parameters = sum(p.numel() for p in model_with_lora.parameters())\n            trainable_parameters = sum(p.numel() for p in model_with_lora.parameters() if p.requires_grad)\n            trainable_percentage = (trainable_parameters / num_parameters) * 100\n            \n            print(f\"Model has {num_parameters:,} total parameters\")\n            print(f\"Model has {trainable_parameters:,} trainable parameters\")\n            print(f\"{trainable_percentage:.2f}% of the parameters are trainable\")\n\n            if torch.cuda.is_available():\n                torch.cuda.empty_cache()\n                gpu_memory = torch.cuda.memory_allocated() / 1024**2  # in MB\n                print(f\"GPU memory allocated: {gpu_memory:.2f} MB\")\n\n            wandb.config.update({\"model/num_parameters\": model.num_parameters()}, allow_val_change=True)\n\n            output_dir = f\"./results_phase2_r{rank}_alpha{lora_alpha}_drop{lora_dropout}_targets{'_'.join(target_matrices)}_bs{fixed_batch_size}_epochs{fixed_epochs}_lr{fixed_learning_rate}\"\n            training_args = TrainingArguments(\n                output_dir=output_dir,\n                evaluation_strategy=\"epoch\",\n                learning_rate=fixed_learning_rate,\n                per_device_train_batch_size=fixed_batch_size,\n                per_device_eval_batch_size=fixed_batch_size,\n                num_train_epochs=fixed_epochs,\n                weight_decay=0.01,\n                save_total_limit=1,\n                save_strategy=\"epoch\",\n                logging_dir=\"./logs\",\n                logging_steps=10,\n                load_best_model_at_end=True,\n            )\n\n            trainer = Trainer(\n                model=model_with_lora,\n                args=training_args,\n                train_dataset=tokenized_train,\n                eval_dataset=tokenized_test,\n                tokenizer=tokenizer,\n                compute_metrics=compute_metrics\n            )\n\n            trainer.train()\n            metrics = trainer.evaluate()\n\n            end_time = time.time()\n            elapsed_time = end_time - start_time\n            print(f\"Training time: {elapsed_time:.2f} seconds\")\n\n            results_phase_2.append({\n                \"Model\": \"ALBERT\",\n                \"Batch Size\": fixed_batch_size,\n                \"Epochs\": fixed_epochs,\n                \"Learning Rate\": fixed_learning_rate,\n                \"Rank\": rank,\n                \"Alpha\": lora_alpha,  # Fixed alpha\n                \"LoRA Dropout\": lora_dropout,\n                \"Target Matrices\": target_matrices,\n                \"Accuracy\": metrics[\"eval_accuracy\"],\n                \"Precision\": metrics[\"eval_precision\"],\n                \"Recall\": metrics[\"eval_recall\"],\n                \"F1-Score\": metrics[\"eval_f1\"]\n            })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T20:30:18.980212Z","iopub.execute_input":"2025-01-05T20:30:18.980543Z","iopub.status.idle":"2025-01-05T22:07:05.130103Z","shell.execute_reply.started":"2025-01-05T20:30:18.980516Z","shell.execute_reply":"2025-01-05T22:07:05.129439Z"}},"outputs":[{"name":"stdout","text":"\nRunning experiment with: Rank: 8, Target Matrices: ['attention.q_lin'], LoRA Dropout: 0.1\nModel has 67,620,868 total parameters\nModel has 665,858 trainable parameters\n0.98% of the parameters are trainable\nGPU memory allocated: 259.04 MB\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 07:09, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.494000</td>\n      <td>0.428150</td>\n      <td>0.845000</td>\n      <td>0.849940</td>\n      <td>0.845000</td>\n      <td>0.844044</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.229700</td>\n      <td>0.279210</td>\n      <td>0.887500</td>\n      <td>0.890226</td>\n      <td>0.887500</td>\n      <td>0.887476</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.311600</td>\n      <td>0.275927</td>\n      <td>0.894000</td>\n      <td>0.895165</td>\n      <td>0.894000</td>\n      <td>0.894024</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.271400</td>\n      <td>0.274655</td>\n      <td>0.892500</td>\n      <td>0.892545</td>\n      <td>0.892500</td>\n      <td>0.892511</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.261800</td>\n      <td>0.273740</td>\n      <td>0.891000</td>\n      <td>0.891101</td>\n      <td>0.891000</td>\n      <td>0.891018</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:21]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 454.02 seconds\n\nRunning experiment with: Rank: 8, Target Matrices: ['attention.q_lin'], LoRA Dropout: 0.2\nModel has 67,620,868 total parameters\nModel has 665,858 trainable parameters\n0.98% of the parameters are trainable\nGPU memory allocated: 282.91 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 07:23, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.499000</td>\n      <td>0.435013</td>\n      <td>0.844000</td>\n      <td>0.849444</td>\n      <td>0.844000</td>\n      <td>0.842960</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.231300</td>\n      <td>0.280165</td>\n      <td>0.887500</td>\n      <td>0.889971</td>\n      <td>0.887500</td>\n      <td>0.887485</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.308300</td>\n      <td>0.276426</td>\n      <td>0.894000</td>\n      <td>0.895081</td>\n      <td>0.894000</td>\n      <td>0.894025</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.272900</td>\n      <td>0.275097</td>\n      <td>0.893000</td>\n      <td>0.893021</td>\n      <td>0.893000</td>\n      <td>0.893007</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.263500</td>\n      <td>0.274169</td>\n      <td>0.891500</td>\n      <td>0.891565</td>\n      <td>0.891500</td>\n      <td>0.891514</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:21]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 467.03 seconds\n\nRunning experiment with: Rank: 8, Target Matrices: ['attention.q_lin', 'attention.k_lin'], LoRA Dropout: 0.1\nModel has 67,694,596 total parameters\nModel has 739,586 trainable parameters\n1.09% of the parameters are trainable\nGPU memory allocated: 283.82 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 07:35, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.444100</td>\n      <td>0.357172</td>\n      <td>0.870000</td>\n      <td>0.870645</td>\n      <td>0.870000</td>\n      <td>0.869818</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.217300</td>\n      <td>0.285500</td>\n      <td>0.890000</td>\n      <td>0.890774</td>\n      <td>0.890000</td>\n      <td>0.890031</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.273800</td>\n      <td>0.278292</td>\n      <td>0.894500</td>\n      <td>0.894990</td>\n      <td>0.894500</td>\n      <td>0.894530</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.248200</td>\n      <td>0.277880</td>\n      <td>0.892000</td>\n      <td>0.892012</td>\n      <td>0.892000</td>\n      <td>0.891974</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.249800</td>\n      <td>0.275829</td>\n      <td>0.893000</td>\n      <td>0.892992</td>\n      <td>0.893000</td>\n      <td>0.892988</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:22]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 479.16 seconds\n\nRunning experiment with: Rank: 8, Target Matrices: ['attention.q_lin', 'attention.k_lin'], LoRA Dropout: 0.2\nModel has 67,694,596 total parameters\nModel has 739,586 trainable parameters\n1.09% of the parameters are trainable\nGPU memory allocated: 284.66 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 07:36, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.446900</td>\n      <td>0.359739</td>\n      <td>0.869500</td>\n      <td>0.870174</td>\n      <td>0.869500</td>\n      <td>0.869312</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.216200</td>\n      <td>0.285174</td>\n      <td>0.892000</td>\n      <td>0.892846</td>\n      <td>0.892000</td>\n      <td>0.892029</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.277200</td>\n      <td>0.278282</td>\n      <td>0.895000</td>\n      <td>0.895463</td>\n      <td>0.895000</td>\n      <td>0.895030</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.253300</td>\n      <td>0.277743</td>\n      <td>0.891000</td>\n      <td>0.891012</td>\n      <td>0.891000</td>\n      <td>0.890974</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.251000</td>\n      <td>0.275947</td>\n      <td>0.891000</td>\n      <td>0.891002</td>\n      <td>0.891000</td>\n      <td>0.890979</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:22]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 480.66 seconds\n\nRunning experiment with: Rank: 8, Target Matrices: ['attention.q_lin', 'attention.k_lin', 'attention.v_lin'], LoRA Dropout: 0.1\nModel has 67,768,324 total parameters\nModel has 813,314 trainable parameters\n1.20% of the parameters are trainable\nGPU memory allocated: 284.94 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 07:45, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.357000</td>\n      <td>0.298979</td>\n      <td>0.883000</td>\n      <td>0.883022</td>\n      <td>0.883000</td>\n      <td>0.883007</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.217200</td>\n      <td>0.279719</td>\n      <td>0.885000</td>\n      <td>0.887652</td>\n      <td>0.885000</td>\n      <td>0.884978</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.295900</td>\n      <td>0.264674</td>\n      <td>0.895000</td>\n      <td>0.895054</td>\n      <td>0.895000</td>\n      <td>0.895013</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.245500</td>\n      <td>0.264079</td>\n      <td>0.896500</td>\n      <td>0.896504</td>\n      <td>0.896500</td>\n      <td>0.896502</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.235000</td>\n      <td>0.262653</td>\n      <td>0.897500</td>\n      <td>0.897501</td>\n      <td>0.897500</td>\n      <td>0.897482</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:22]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 489.69 seconds\n\nRunning experiment with: Rank: 8, Target Matrices: ['attention.q_lin', 'attention.k_lin', 'attention.v_lin'], LoRA Dropout: 0.2\nModel has 67,768,324 total parameters\nModel has 813,314 trainable parameters\n1.20% of the parameters are trainable\nGPU memory allocated: 285.78 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 07:45, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.360300</td>\n      <td>0.298756</td>\n      <td>0.883000</td>\n      <td>0.883009</td>\n      <td>0.883000</td>\n      <td>0.883004</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.216100</td>\n      <td>0.280613</td>\n      <td>0.885500</td>\n      <td>0.888219</td>\n      <td>0.885500</td>\n      <td>0.885475</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.298500</td>\n      <td>0.264825</td>\n      <td>0.894000</td>\n      <td>0.894054</td>\n      <td>0.894000</td>\n      <td>0.894013</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.247300</td>\n      <td>0.263963</td>\n      <td>0.896000</td>\n      <td>0.896020</td>\n      <td>0.896000</td>\n      <td>0.896007</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.237900</td>\n      <td>0.262672</td>\n      <td>0.896500</td>\n      <td>0.896495</td>\n      <td>0.896500</td>\n      <td>0.896486</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:22]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 489.57 seconds\n\nRunning experiment with: Rank: 16, Target Matrices: ['attention.q_lin'], LoRA Dropout: 0.1\nModel has 67,842,052 total parameters\nModel has 887,042 trainable parameters\n1.31% of the parameters are trainable\nGPU memory allocated: 285.50 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 07:46, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.294800</td>\n      <td>0.273457</td>\n      <td>0.893000</td>\n      <td>0.893100</td>\n      <td>0.893000</td>\n      <td>0.893018</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.189100</td>\n      <td>0.274529</td>\n      <td>0.888000</td>\n      <td>0.889729</td>\n      <td>0.888000</td>\n      <td>0.888010</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.268200</td>\n      <td>0.264465</td>\n      <td>0.897500</td>\n      <td>0.897734</td>\n      <td>0.897500</td>\n      <td>0.897428</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.214400</td>\n      <td>0.262977</td>\n      <td>0.897500</td>\n      <td>0.897537</td>\n      <td>0.897500</td>\n      <td>0.897468</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.212200</td>\n      <td>0.263420</td>\n      <td>0.897000</td>\n      <td>0.897178</td>\n      <td>0.897000</td>\n      <td>0.896937</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:22]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 490.31 seconds\n\nRunning experiment with: Rank: 16, Target Matrices: ['attention.q_lin'], LoRA Dropout: 0.2\nModel has 67,842,052 total parameters\nModel has 887,042 trainable parameters\n1.31% of the parameters are trainable\nGPU memory allocated: 286.35 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 07:46, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.273300</td>\n      <td>0.274624</td>\n      <td>0.900000</td>\n      <td>0.900031</td>\n      <td>0.900000</td>\n      <td>0.899971</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.171400</td>\n      <td>0.271528</td>\n      <td>0.896000</td>\n      <td>0.897001</td>\n      <td>0.896000</td>\n      <td>0.896026</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.240800</td>\n      <td>0.271992</td>\n      <td>0.896500</td>\n      <td>0.897358</td>\n      <td>0.896500</td>\n      <td>0.896342</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.187800</td>\n      <td>0.264806</td>\n      <td>0.904500</td>\n      <td>0.904708</td>\n      <td>0.904500</td>\n      <td>0.904439</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.194300</td>\n      <td>0.265618</td>\n      <td>0.905500</td>\n      <td>0.905749</td>\n      <td>0.905500</td>\n      <td>0.905433</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:22]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 490.72 seconds\n\nRunning experiment with: Rank: 16, Target Matrices: ['attention.q_lin', 'attention.k_lin'], LoRA Dropout: 0.1\nModel has 67,915,780 total parameters\nModel has 960,770 trainable parameters\n1.41% of the parameters are trainable\nGPU memory allocated: 286.91 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 07:47, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.268900</td>\n      <td>0.267425</td>\n      <td>0.891500</td>\n      <td>0.892309</td>\n      <td>0.891500</td>\n      <td>0.891530</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.182300</td>\n      <td>0.279032</td>\n      <td>0.890000</td>\n      <td>0.892176</td>\n      <td>0.890000</td>\n      <td>0.889996</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.269600</td>\n      <td>0.260321</td>\n      <td>0.898000</td>\n      <td>0.898009</td>\n      <td>0.898000</td>\n      <td>0.898003</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.204200</td>\n      <td>0.263646</td>\n      <td>0.900500</td>\n      <td>0.900502</td>\n      <td>0.900500</td>\n      <td>0.900483</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.196100</td>\n      <td>0.267671</td>\n      <td>0.903000</td>\n      <td>0.903406</td>\n      <td>0.903000</td>\n      <td>0.902909</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:22]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 491.24 seconds\n\nRunning experiment with: Rank: 16, Target Matrices: ['attention.q_lin', 'attention.k_lin'], LoRA Dropout: 0.2\nModel has 67,915,780 total parameters\nModel has 960,770 trainable parameters\n1.41% of the parameters are trainable\nGPU memory allocated: 287.75 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 07:46, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.248600</td>\n      <td>0.264657</td>\n      <td>0.899500</td>\n      <td>0.899511</td>\n      <td>0.899500</td>\n      <td>0.899478</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.184900</td>\n      <td>0.280248</td>\n      <td>0.892000</td>\n      <td>0.894065</td>\n      <td>0.892000</td>\n      <td>0.892000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.266200</td>\n      <td>0.259999</td>\n      <td>0.901000</td>\n      <td>0.901020</td>\n      <td>0.901000</td>\n      <td>0.901006</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.200900</td>\n      <td>0.266241</td>\n      <td>0.904000</td>\n      <td>0.904000</td>\n      <td>0.904000</td>\n      <td>0.903985</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.192800</td>\n      <td>0.270340</td>\n      <td>0.904000</td>\n      <td>0.904462</td>\n      <td>0.904000</td>\n      <td>0.903903</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:22]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 490.96 seconds\n\nRunning experiment with: Rank: 16, Target Matrices: ['attention.q_lin', 'attention.k_lin', 'attention.v_lin'], LoRA Dropout: 0.1\nModel has 67,989,508 total parameters\nModel has 1,034,498 trainable parameters\n1.52% of the parameters are trainable\nGPU memory allocated: 288.32 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 07:47, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.354800</td>\n      <td>0.298614</td>\n      <td>0.882000</td>\n      <td>0.881990</td>\n      <td>0.882000</td>\n      <td>0.881991</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.217100</td>\n      <td>0.284569</td>\n      <td>0.881500</td>\n      <td>0.885340</td>\n      <td>0.881500</td>\n      <td>0.881424</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.291900</td>\n      <td>0.262738</td>\n      <td>0.894500</td>\n      <td>0.894544</td>\n      <td>0.894500</td>\n      <td>0.894511</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.244700</td>\n      <td>0.261674</td>\n      <td>0.895000</td>\n      <td>0.894997</td>\n      <td>0.895000</td>\n      <td>0.894984</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.233600</td>\n      <td>0.260096</td>\n      <td>0.895500</td>\n      <td>0.895536</td>\n      <td>0.895500</td>\n      <td>0.895467</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:22]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 491.55 seconds\n\nRunning experiment with: Rank: 16, Target Matrices: ['attention.q_lin', 'attention.k_lin', 'attention.v_lin'], LoRA Dropout: 0.2\nModel has 67,989,508 total parameters\nModel has 1,034,498 trainable parameters\n1.52% of the parameters are trainable\nGPU memory allocated: 289.16 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [470/470 07:46, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.359500</td>\n      <td>0.298737</td>\n      <td>0.882000</td>\n      <td>0.881990</td>\n      <td>0.882000</td>\n      <td>0.881987</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.216000</td>\n      <td>0.284842</td>\n      <td>0.881000</td>\n      <td>0.885072</td>\n      <td>0.881000</td>\n      <td>0.880913</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.293400</td>\n      <td>0.262750</td>\n      <td>0.895000</td>\n      <td>0.895075</td>\n      <td>0.895000</td>\n      <td>0.895015</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.246300</td>\n      <td>0.261745</td>\n      <td>0.895000</td>\n      <td>0.895000</td>\n      <td>0.895000</td>\n      <td>0.895000</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.235900</td>\n      <td>0.260355</td>\n      <td>0.894500</td>\n      <td>0.894535</td>\n      <td>0.894500</td>\n      <td>0.894467</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:22]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Training time: 490.92 seconds\ntime: 1h 36min 46s (started: 2025-01-05 20:30:18 +00:00)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Testing evaluations saved\nresults_df_phase_2 = pd.DataFrame(results_phase_2)\nresults_df_phase_2.to_csv(\"7_FT_ALBERT_Experiments_FixedTrainingHyp.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T22:15:32.197900Z","iopub.execute_input":"2025-01-05T22:15:32.198268Z","iopub.status.idle":"2025-01-05T22:15:32.207908Z","shell.execute_reply.started":"2025-01-05T22:15:32.198236Z","shell.execute_reply":"2025-01-05T22:15:32.207175Z"}},"outputs":[{"name":"stdout","text":"time: 6.25 ms (started: 2025-01-05 22:15:32 +00:00)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}